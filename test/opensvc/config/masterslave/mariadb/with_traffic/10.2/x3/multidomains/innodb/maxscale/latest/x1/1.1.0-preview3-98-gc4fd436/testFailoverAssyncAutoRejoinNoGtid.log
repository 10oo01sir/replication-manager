2017/08/04 00:32:00 [ux_dck_zpool_loop] INFO  - hostlist: 192.168.100.70,192.168.100.71,192.168.100.72 [192.168.100.70 192.168.100.71 192.168.100.72]
2017/08/04 00:32:00 [ux_dck_zpool_loop] INFO  - Loading 1 proxies
2017/08/04 00:32:00 [ux_dck_zpool_loop] INFO  - Loading Maxscale...
2017/08/04 00:32:00 [ux_dck_zpool_loop] INFO  - Failover in automatic mode
2017/08/04 00:32:00 [ux_dck_zpool_loop] ERROR - File error: open /var/lib/replication-manager/ux_dck_zpool_loop.json: no such file or directory

2017/08/04 00:32:02 [ux_dck_zpool_loop] TESTI - testFailoverAssyncAutoRejoinNoGtid
2017/08/04 00:32:03 [ux_dck_zpool_loop] INFO  - Init maxscale 192.168.100.50 3307
2017/08/04 00:32:03 [ux_dck_zpool_loop] ERROR - MaxScale server name undiscovered
2017/08/04 00:32:03 [ux_dck_zpool_loop] STATE - WARN0056 No compression of binlog on slave 192.168.100.71
2017/08/04 00:32:03 [ux_dck_zpool_loop] STATE - WARN0058 No GTID strict mode on slave 192.168.100.71
2017/08/04 00:32:03 [ux_dck_zpool_loop] STATE - WARN0068 No compression of binlog on slave 192.168.100.72
2017/08/04 00:32:03 [ux_dck_zpool_loop] STATE - WARN0070 No GTID strict mode on master 192.168.100.72
2017/08/04 00:32:03 [ux_dck_zpool_loop] STATE - WARN0050 No Heartbeat <= 1s on slave 192.168.100.71
2017/08/04 00:32:04 [ux_dck_zpool_loop] INFO  - Provisioning delete service 551bb32c-aaae-43f0-a740-d43af74db035
2017/08/04 00:32:11 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/04 00:32:14 [ux_dck_zpool_loop] INFO  - 22:32:08,740 disk#00        INFO    already provisionned
22:32:08,803 disk#00        INFO    loop /srv/4832677178583133704_docker.dsk is already up
22:32:08,872 disk#0000      INFO    already provisionned
22:32:08,879 disk#0000      INFO    zp4832677178583133704_00 is already up
22:32:08,887 disk#01        INFO    already provisionned
22:32:08,955 disk#01        INFO    loop /srv/4832677178583133704_pod01.dsk is already up
22:32:09,029 disk#1001      INFO    already provisionned
22:32:09,037 disk#1001      INFO    zp4832677178583133704_pod01 is already up
22:32:09,052 fs#00          INFO    /sbin/zfs set refquota=2048M zp4832677178583133704_00/docker
22:32:09,060 fs#00          INFO    provisioned
22:32:09,070 fs#00          INFO    zfs zp4832677178583133704_00/docker@/srv/4832677178583133704/docker is already mounted
22:32:09,096 fs#01          INFO    /sbin/zfs set refquota=1024M zp4832677178583133704_pod01/pod01
22:32:09,118 fs#01          INFO    provisioned
22:32:09,137 fs#01          INFO    zfs zp4832677178583133704_pod01/pod01@/srv/4832677178583133704/pod01 is already mounted
22:32:09,138 fs#01          INFO    /usr/bin/svcmgr -s 4832677178583133704 push service status;/usr/bin/svcmgr -s 4832677178583133704 compliance fix --attach --moduleset mariadb.svc.mrm.db
22:32:11,357 fs#01          INFO    output:
moduleset mariadb.svc.mrm.db attached
=========================== mariadb.svc.mrm.db.cnf ===========================
ACTION:   check
file /srv/4832677178583133704/pod01/etc/mysql/spider.cnf is ok
ERR: OSVC_COMP_DB_CNF_WSREP undefined substitution variable: GCOMM
file /srv/4832677178583133704/pod01/etc/mysql/myrock.cnf is ok
ERR: failed to concatenate  to rules list
file /srv/4832677178583133704/pod01/etc/mysql/compress.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/rc.d/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/threadpool.cnf is ok
file /srv/4832677178583133704/pod01/data/.system/tmp/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/aria.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/tokudb.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/noquerycache.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/mysqlgtid.cnf is ok
file /srv/4832677178583133704/pod01/data/.system/aria/ is ok
file /srv/4832677178583133704/pod01/data/.system/repl/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/loggeneral.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/custom/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/security.cnf is ok
file /srv/4832677178583133704/pod01/data/.system/innodb/redo/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/nomogslaveupdates.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/semisync.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/audit.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/multidomains.cnf is ok
file /srv/4832677178583133704/pod01/data/.system/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/my.cnf is ok
file /srv/4832677178583133704/pod01/init/ is ok
file /srv/4832677178583133704/pod01/data/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/rpl_ptr.cnf is ok
file /srv/4832677178583133704/pod01/data/.system/tokudb/ is ok
file /srv/4832677178583133704/pod01/data/.system/innodb/undo/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/innodb.cnf is ok
file /srv/4832677178583133704/pod01/init/launcher is ok
file /srv/4832677178583133704/pod01/data/.system/innodb/ is ok
file /srv/4832677178583133704/pod01/init/start is ok
file /srv/4832677178583133704/pod01/etc/mysql/optimizer.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/optimizer.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/sharedpool.cnf is ok
file /srv/4832677178583133704/pod01/init/MYSQL_ROOT_PASSWORD is ok
file /srv/4832677178583133704/pod01/etc/mysql/smallredolog.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/logsqlerror.cnf is ok
file /srv/4832677178583133704/pod01/data/.system/logs/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/logs.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/logslow.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/network.cnf is ok
symlink /srv/4832677178583133704/pod01/etc/mysql/rc.d/smallredolog.cnf -> ../smallredolog.cnf is ok
symlink /srv/4832677178583133704/pod01/etc/mysql/rc.d/logslow.cnf -> ../logslow.cnf is ok
symlink /srv/4832677178583133704/pod01/etc/mysql/rc.d/threadpool.cnf -> ../threadpool.cnf is ok
symlink /srv/4832677178583133704/pod01/etc/mysql/rc.d/noquerycache.cnf -> ../noquerycache.cnf is ok
symlink /srv/4832677178583133704/pod01/etc/mysql/rc.d/semisync.cnf -> ../semisync.cnf is ok
symlink /srv/4832677178583133704/pod01/etc/mysql/rc.d/innodb.cnf -> ../innodb.cnf is ok
symlink /srv/4832677178583133704/pod01/etc/mysql/rc.d/multidomains.cnf -> ../multidomains.cnf is ok
STATUS:   ok
check passed, skip fix
=================================== digest ===================================
0 n/a
1 passed
 mariadb.svc.mrm.db.cnf
0 error
total duration: 0:00:00.208834
22:32:11,437 container#0001 INFO    container docker container 4832677178583133704.container.0001@busybox:latest already started on node-1-1.vdc.opensvc.com
22:32:11,483 ip#01          INFO    skip allocate: an ip is already defined
22:32:11,547 ip#01          INFO    192.168.100.70 is already up on br0
22:32:11,682 container#2001 INFO    container docker container 4832677178583133704.container.2001@mariadb:10.2 already started on node-1-1.vdc.opensvc.com
22:32:11,909                INFO    send /etc/opensvc/4832677178583133704.conf to collector
22:32:11,910                INFO    update /var/lib/opensvc/4832677178583133704/last_pushed_config timestamp
a stack has been saved to the rpc log

2017/08/04 00:32:15 [ux_dck_zpool_loop] STATE - WARN0045 CLOSING Provision task is in queue
2017/08/04 00:32:16 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/04 00:32:16 [ux_dck_zpool_loop] INFO  - Database started
2017/08/04 00:32:17 [ux_dck_zpool_loop] INFO  - Provisioning delete service 2946e818-7157-45f3-b07f-5e45020a649a
2017/08/04 00:32:23 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/04 00:32:27 [ux_dck_zpool_loop] STATE - WARN0045 CLOSING Provision task is in queue
2017/08/04 00:32:27 [ux_dck_zpool_loop] INFO  - 22:32:21,701 disk#00        INFO    already provisionned
22:32:21,770 disk#00        INFO    loop /srv/17311646700765639015_docker.dsk is already up
22:32:21,846 disk#0000      INFO    already provisionned
22:32:21,853 disk#0000      INFO    zp17311646700765639015_00 is already up
22:32:21,860 disk#01        INFO    already provisionned
22:32:21,933 disk#01        INFO    loop /srv/17311646700765639015_pod01.dsk is already up
22:32:22,011 disk#1001      INFO    already provisionned
22:32:22,019 disk#1001      INFO    zp17311646700765639015_pod01 is already up
22:32:22,034 fs#00          INFO    /sbin/zfs set refquota=2048M zp17311646700765639015_00/docker
22:32:22,043 fs#00          INFO    provisioned
22:32:22,054 fs#00          INFO    zfs zp17311646700765639015_00/docker@/srv/17311646700765639015/docker is already mounted
22:32:22,071 fs#01          INFO    /sbin/zfs set refquota=1024M zp17311646700765639015_pod01/pod01
22:32:22,084 fs#01          INFO    provisioned
22:32:22,093 fs#01          INFO    zfs zp17311646700765639015_pod01/pod01@/srv/17311646700765639015/pod01 is already mounted
22:32:22,094 fs#01          INFO    /usr/bin/svcmgr -s 17311646700765639015 push service status;/usr/bin/svcmgr -s 17311646700765639015 compliance fix --attach --moduleset mariadb.svc.mrm.db
22:32:24,283 fs#01          INFO    output:
moduleset mariadb.svc.mrm.db attached
=========================== mariadb.svc.mrm.db.cnf ===========================
ACTION:   check
file /srv/17311646700765639015/pod01/etc/mysql/spider.cnf is ok
ERR: OSVC_COMP_DB_CNF_WSREP undefined substitution variable: GCOMM
file /srv/17311646700765639015/pod01/etc/mysql/myrock.cnf is ok
ERR: failed to concatenate  to rules list
file /srv/17311646700765639015/pod01/etc/mysql/compress.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/rc.d/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/threadpool.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/tmp/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/aria.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/tokudb.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/noquerycache.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/mysqlgtid.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/aria/ is ok
file /srv/17311646700765639015/pod01/data/.system/repl/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/loggeneral.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/custom/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/security.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/innodb/redo/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/nomogslaveupdates.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/semisync.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/audit.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/multidomains.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/my.cnf is ok
file /srv/17311646700765639015/pod01/init/ is ok
file /srv/17311646700765639015/pod01/data/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/rpl_ptr.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/tokudb/ is ok
file /srv/17311646700765639015/pod01/data/.system/innodb/undo/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/innodb.cnf is ok
file /srv/17311646700765639015/pod01/init/launcher is ok
file /srv/17311646700765639015/pod01/data/.system/innodb/ is ok
file /srv/17311646700765639015/pod01/init/start is ok
file /srv/17311646700765639015/pod01/etc/mysql/optimizer.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/optimizer.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/sharedpool.cnf is ok
file /srv/17311646700765639015/pod01/init/MYSQL_ROOT_PASSWORD is ok
file /srv/17311646700765639015/pod01/etc/mysql/smallredolog.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/logsqlerror.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/logs/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/logs.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/logslow.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/network.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/smallredolog.cnf -> ../smallredolog.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/logslow.cnf -> ../logslow.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/threadpool.cnf -> ../threadpool.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/noquerycache.cnf -> ../noquerycache.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/semisync.cnf -> ../semisync.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/innodb.cnf -> ../innodb.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/multidomains.cnf -> ../multidomains.cnf is ok
STATUS:   ok
check passed, skip fix
=================================== digest ===================================
0 n/a
1 passed
 mariadb.svc.mrm.db.cnf
0 error
total duration: 0:00:00.209178
22:32:24,363 container#0001 INFO    container docker container 17311646700765639015.container.0001@busybox:latest already started on node-1-2.vdc.opensvc.com
22:32:24,408 ip#01          INFO    skip allocate: an ip is already defined
22:32:24,474 ip#01          INFO    192.168.100.71 is already up on br0
22:32:24,615 container#2001 INFO    container docker container 17311646700765639015.container.2001@mariadb:10.2 already started on node-1-2.vdc.opensvc.com
22:32:24,974                INFO    send /etc/opensvc/17311646700765639015.conf to collector
22:32:24,975                INFO    update /var/lib/opensvc/17311646700765639015/last_pushed_config timestamp
a stack has been saved to the rpc log

2017/08/04 00:32:29 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/04 00:32:29 [ux_dck_zpool_loop] INFO  - Database started
2017/08/04 00:32:30 [ux_dck_zpool_loop] INFO  - Provisioning delete service 2bf11c7a-60c5-4aab-977b-e857e21d1318
2017/08/04 00:32:37 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/04 00:32:40 [ux_dck_zpool_loop] INFO  - 22:32:34,801 disk#00        INFO    already provisionned
22:32:34,879 disk#00        INFO    loop /srv/13228523588305620563_docker.dsk is already up
22:32:34,956 disk#0000      INFO    already provisionned
22:32:34,964 disk#0000      INFO    zp13228523588305620563_00 is already up
22:32:34,971 disk#01        INFO    already provisionned
22:32:35,039 disk#01        INFO    loop /srv/13228523588305620563_pod01.dsk is already up
22:32:35,109 disk#1001      INFO    already provisionned
22:32:35,120 disk#1001      INFO    zp13228523588305620563_pod01 is already up
22:32:35,143 fs#00          INFO    /sbin/zfs set refquota=2048M zp13228523588305620563_00/docker
22:32:35,155 fs#00          INFO    provisioned
22:32:35,169 fs#00          INFO    zfs zp13228523588305620563_00/docker@/srv/13228523588305620563/docker is already mounted
22:32:35,186 fs#01          INFO    /sbin/zfs set refquota=1024M zp13228523588305620563_pod01/pod01
22:32:35,204 fs#01          INFO    provisioned
22:32:35,214 fs#01          INFO    zfs zp13228523588305620563_pod01/pod01@/srv/13228523588305620563/pod01 is already mounted
22:32:35,214 fs#01          INFO    /usr/bin/svcmgr -s 13228523588305620563 push service status;/usr/bin/svcmgr -s 13228523588305620563 compliance fix --attach --moduleset mariadb.svc.mrm.db
22:32:37,369 fs#01          INFO    output:
moduleset mariadb.svc.mrm.db attached
=========================== mariadb.svc.mrm.db.cnf ===========================
ACTION:   check
file /srv/13228523588305620563/pod01/etc/mysql/spider.cnf is ok
ERR: OSVC_COMP_DB_CNF_WSREP undefined substitution variable: GCOMM
file /srv/13228523588305620563/pod01/etc/mysql/myrock.cnf is ok
ERR: failed to concatenate  to rules list
file /srv/13228523588305620563/pod01/etc/mysql/compress.cnf is ok
file /srv/13228523588305620563/pod01/etc/mysql/rc.d/ is ok
file /srv/13228523588305620563/pod01/etc/mysql/threadpool.cnf is ok
file /srv/13228523588305620563/pod01/data/.system/tmp/ is ok
file /srv/13228523588305620563/pod01/etc/mysql/aria.cnf is ok
file /srv/13228523588305620563/pod01/etc/mysql/tokudb.cnf is ok
file /srv/13228523588305620563/pod01/etc/mysql/noquerycache.cnf is ok
file /srv/13228523588305620563/pod01/etc/mysql/ is ok
file /srv/13228523588305620563/pod01/etc/mysql/mysqlgtid.cnf is ok
file /srv/13228523588305620563/pod01/data/.system/aria/ is ok
file /srv/13228523588305620563/pod01/data/.system/repl/ is ok
file /srv/13228523588305620563/pod01/etc/mysql/loggeneral.cnf is ok
file /srv/13228523588305620563/pod01/etc/mysql/custom/ is ok
file /srv/13228523588305620563/pod01/etc/mysql/security.cnf is ok
file /srv/13228523588305620563/pod01/data/.system/innodb/redo/ is ok
file /srv/13228523588305620563/pod01/etc/mysql/nomogslaveupdates.cnf is ok
file /srv/13228523588305620563/pod01/etc/mysql/semisync.cnf is ok
file /srv/13228523588305620563/pod01/etc/mysql/audit.cnf is ok
file /srv/13228523588305620563/pod01/etc/mysql/multidomains.cnf is ok
file /srv/13228523588305620563/pod01/data/.system/ is ok
file /srv/13228523588305620563/pod01/etc/mysql/my.cnf is ok
file /srv/13228523588305620563/pod01/init/ is ok
file /srv/13228523588305620563/pod01/data/ is ok
file /srv/13228523588305620563/pod01/etc/mysql/rpl_ptr.cnf is ok
file /srv/13228523588305620563/pod01/data/.system/tokudb/ is ok
file /srv/13228523588305620563/pod01/data/.system/innodb/undo/ is ok
file /srv/13228523588305620563/pod01/etc/mysql/innodb.cnf is ok
file /srv/13228523588305620563/pod01/init/launcher is ok
file /srv/13228523588305620563/pod01/data/.system/innodb/ is ok
file /srv/13228523588305620563/pod01/init/start is ok
file /srv/13228523588305620563/pod01/etc/mysql/optimizer.cnf is ok
file /srv/13228523588305620563/pod01/etc/mysql/optimizer.cnf is ok
file /srv/13228523588305620563/pod01/etc/mysql/sharedpool.cnf is ok
file /srv/13228523588305620563/pod01/init/MYSQL_ROOT_PASSWORD is ok
file /srv/13228523588305620563/pod01/etc/mysql/smallredolog.cnf is ok
file /srv/13228523588305620563/pod01/etc/mysql/logsqlerror.cnf is ok
file /srv/13228523588305620563/pod01/data/.system/logs/ is ok
file /srv/13228523588305620563/pod01/etc/mysql/logs.cnf is ok
file /srv/13228523588305620563/pod01/etc/mysql/logslow.cnf is ok
file /srv/13228523588305620563/pod01/etc/mysql/network.cnf is ok
symlink /srv/13228523588305620563/pod01/etc/mysql/rc.d/smallredolog.cnf -> ../smallredolog.cnf is ok
symlink /srv/13228523588305620563/pod01/etc/mysql/rc.d/logslow.cnf -> ../logslow.cnf is ok
symlink /srv/13228523588305620563/pod01/etc/mysql/rc.d/threadpool.cnf -> ../threadpool.cnf is ok
symlink /srv/13228523588305620563/pod01/etc/mysql/rc.d/noquerycache.cnf -> ../noquerycache.cnf is ok
symlink /srv/13228523588305620563/pod01/etc/mysql/rc.d/semisync.cnf -> ../semisync.cnf is ok
symlink /srv/13228523588305620563/pod01/etc/mysql/rc.d/innodb.cnf -> ../innodb.cnf is ok
symlink /srv/13228523588305620563/pod01/etc/mysql/rc.d/multidomains.cnf -> ../multidomains.cnf is ok
STATUS:   ok
check passed, skip fix
=================================== digest ===================================
0 n/a
1 passed
 mariadb.svc.mrm.db.cnf
0 error
total duration: 0:00:00.207976
22:32:37,448 container#0001 INFO    container docker container 13228523588305620563.container.0001@busybox:latest already started on node-1-1.vdc.opensvc.com
22:32:37,492 ip#01          INFO    skip allocate: an ip is already defined
22:32:37,559 ip#01          INFO    192.168.100.72 is already up on br0
22:32:37,694 container#2001 INFO    container docker container 13228523588305620563.container.2001@mariadb:10.2 already started on node-1-1.vdc.opensvc.com
22:32:37,921                INFO    send /etc/opensvc/13228523588305620563.conf to collector
22:32:37,922                INFO    update /var/lib/opensvc/13228523588305620563/last_pushed_config timestamp
a stack has been saved to the rpc log

2017/08/04 00:32:41 [ux_dck_zpool_loop] STATE - WARN0045 CLOSING Provision task is in queue
2017/08/04 00:32:42 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/04 00:32:42 [ux_dck_zpool_loop] INFO  - Database started
2017/08/04 00:32:47 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/04 00:32:51 [ux_dck_zpool_loop] STATE - WARN0045 CLOSING Provision task is in queue
2017/08/04 00:32:51 [ux_dck_zpool_loop] INFO  - 22:32:45,763 disk#00        INFO    already provisionned
22:32:45,833 disk#00        INFO    loop /srv/10940044185188150515_docker.dsk is already up
22:32:45,899 disk#0000      INFO    already provisionned
22:32:45,906 disk#0000      INFO    zp10940044185188150515_00 is already up
22:32:45,913 disk#01        INFO    already provisionned
22:32:45,978 disk#01        INFO    loop /srv/10940044185188150515_pod01.dsk is already up
22:32:46,059 disk#1001      INFO    already provisionned
22:32:46,066 disk#1001      INFO    zp10940044185188150515_pod01 is already up
22:32:46,083 fs#00          INFO    /sbin/zfs set refquota=2048M zp10940044185188150515_00/docker
22:32:46,091 fs#00          INFO    provisioned
22:32:46,101 fs#00          INFO    zfs zp10940044185188150515_00/docker@/srv/10940044185188150515/docker is already mounted
22:32:46,117 fs#01          INFO    /sbin/zfs set refquota=1024M zp10940044185188150515_pod01/pod01
22:32:46,126 fs#01          INFO    provisioned
22:32:46,136 fs#01          INFO    zfs zp10940044185188150515_pod01/pod01@/srv/10940044185188150515/pod01 is already mounted
22:32:46,137 fs#01          INFO    /usr/bin/svcmgr -s 10940044185188150515 push service status;/usr/bin/svcmgr -s 10940044185188150515 compliance fix --attach --moduleset mariadb.svc.mrm.proxy
22:32:48,129 fs#01          INFO    output:
moduleset mariadb.svc.mrm.proxy is already attached to this service
========================= mariadb.svc.mrm.proxy.cnf ==========================
ACTION:   check
file //srv/10940044185188150515/pod01/conf/maxscale.cnf is ok
file /srv/10940044185188150515/pod01/init/launcher is ok
file //srv/10940044185188150515/pod01/log/ is ok
file //srv/10940044185188150515/pod01/data/ is ok
file //srv/10940044185188150515/pod01/conf/config-haproxy.toml is ok
file //srv/10940044185188150515/pod01/init/ is ok
file //srv/10940044185188150515/pod01/conf/ is ok
file //srv/10940044185188150515/pod01/conf/keepalived.conf is ok
file //srv/10940044185188150515/pod01/conf/config.toml is ok
STATUS:   ok
check passed, skip fix
=================================== digest ===================================
0 n/a
1 passed
 mariadb.svc.mrm.proxy.cnf
0 error
total duration: 0:00:00.107879
22:32:48,206 container#0001 INFO    container docker container 10940044185188150515.container.0001@busybox:latest already started on node-1-2.vdc.opensvc.com
22:32:48,251 ip#01          INFO    skip allocate: an ip is already defined
22:32:48,318 ip#01          INFO    192.168.100.50 is already up on br0
22:32:48,462 container#2001 INFO    container docker container 10940044185188150515.container.2001@asosso/maxscale:latest already started on node-1-2.vdc.opensvc.com
22:32:48,738                INFO    send /etc/opensvc/10940044185188150515.conf to collector
22:32:48,739                INFO    update /var/lib/opensvc/10940044185188150515/last_pushed_config timestamp

2017/08/04 00:32:54 [ux_dck_zpool_loop] INFO  - Cleaning up replication on existing servers
2017/08/04 00:32:56 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.72
2017/08/04 00:32:56 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.72
2017/08/04 00:32:56 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/04 00:32:56 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/04 00:32:56 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/04 00:32:56 [ux_dck_zpool_loop] STATE - ERR00012 Could not find a master in topology
2017/08/04 00:32:56 [ux_dck_zpool_loop] STATE - ERR00021 All cluster down in non-interactive mode
2017/08/04 00:32:56 [ux_dck_zpool_loop] STATE - ERR00010 Could not find a slave in topology
2017/08/04 00:33:04 [ux_dck_zpool_loop] INFO  - Environment bootstrapped with old replication style and 192.168.100.70 as master
2017/08/04 00:33:04 [ux_dck_zpool_loop] INFO  - Environment bootstrapped with old replication style and 192.168.100.70 as master
2017/08/04 00:33:04 [ux_dck_zpool_loop] TEST: Waiting Bootstrap and discovery
2017/08/04 00:33:05 [ux_dck_zpool_loop] STATE - ERR00010 CLOSING Could not find a slave in topology
2017/08/04 00:33:05 [ux_dck_zpool_loop] STATE - ERR00012 CLOSING Could not find a master in topology
2017/08/04 00:33:05 [ux_dck_zpool_loop] STATE - ERR00021 CLOSING All cluster down in non-interactive mode
2017/08/04 00:33:05 [ux_dck_zpool_loop] STATE - WARN0051 No GTID replication on slave 192.168.100.71
2017/08/04 00:33:05 [ux_dck_zpool_loop] STATE - WARN0056 No compression of binlog on slave 192.168.100.71
2017/08/04 00:33:05 [ux_dck_zpool_loop] STATE - WARN0058 No GTID strict mode on slave 192.168.100.71
2017/08/04 00:33:05 [ux_dck_zpool_loop] STATE - WARN0068 No compression of binlog on slave 192.168.100.70
2017/08/04 00:33:05 [ux_dck_zpool_loop] STATE - WARN0070 No GTID strict mode on master 192.168.100.70
2017/08/04 00:33:05 [ux_dck_zpool_loop] STATE - WARN0050 No Heartbeat <= 1s on slave 192.168.100.71
2017/08/04 00:33:06 [ux_dck_zpool_loop] TEST  - Waiting Bootstrap and discovery
2017/08/04 00:33:06 [ux_dck_zpool_loop] TEST  - Cluster is Bootstraped and discovery
2017/08/04 00:33:06 [ux_dck_zpool_loop] INFO  - Init maxscale 192.168.100.50 3307
2017/08/04 00:33:11 [ux_dck_zpool_loop] STATE - ERR00017 Unable to fetch MaxScale monitoring information
2017/08/04 00:33:11 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/04 00:33:11 [ux_dck_zpool_loop] STATE - ERR00017 CLOSING Unable to fetch MaxScale monitoring information
2017/08/04 00:33:11 [ux_dck_zpool_loop] TEST  - Starting Test testFailoverAssyncAutoRejoinNoGtid
2017/08/04 00:33:11 [ux_dck_zpool_loop] BENCH - /usr/local/bin/sysbench --test=oltp --oltp-table-size=10000 --mysql-db=test --mysql-user=root --mysql-password=mariadb --mysql-host=127.0.0.1 --mysql-port=3306 --max-time=60 --oltp-test-mode=complex  --max-requests=0 --num-threads=4 cleanup
2017/08/04 00:33:12 [ux_dck_zpool_loop] ERROR - exit status 1
2017/08/04 00:33:12 [ux_dck_zpool_loop] BENCH - /usr/local/bin/sysbench --test=oltp --oltp-table-size=1000000 --mysql-db=test --mysql-user=root --mysql-password=mariadb --mysql-host=127.0.0.1 --mysql-port=3306 --max-time=60 --oltp-test-mode=complex  --max-requests=0 --num-threads=4 prepare
2017/08/04 00:33:12 [ux_dck_zpool_loop] ERROR - exit status 1
2017/08/04 00:33:12 [ux_dck_zpool_loop] BENCH - /usr/local/bin/sysbench --test=oltp --oltp-table-size=1000000 --mysql-db=test --mysql-user=root --mysql-password=mariadb --mysql-host=127.0.0.1 --mysql-port=3306 --max-time=60--oltp-test-mode=complex --max-requests=0 --num-threads=4 run
2017/08/04 00:33:12 [ux_dck_zpool_loop] ERROR - exit status 1
2017/08/04 00:33:17 [ux_dck_zpool_loop] TEST  - Waiting Failover end
2017/08/04 00:33:18 [ux_dck_zpool_loop] ERROR - Error 2003: Lost connection to backend server.
2017/08/04 00:33:18 [ux_dck_zpool_loop] ERROR - Error 2003: Lost connection to backend server.
2017/08/04 00:33:18 [ux_dck_zpool_loop] ERROR - Error 2003: Lost connection to backend server.
2017/08/04 00:33:18 [ux_dck_zpool_loop] ERROR - Error 2003: Lost connection to backend server.
2017/08/04 00:33:18 [ux_dck_zpool_loop] INFO  - Master Failure detected! Retry 1/3
2017/08/04 00:33:18 [ux_dck_zpool_loop] ALERT - Server 192.168.100.70 state changed from Master to Suspect
2017/08/04 00:33:18 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/04 00:33:18 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/04 00:33:18 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/04 00:33:18 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/04 00:33:19 [ux_dck_zpool_loop] TEST  - Waiting Failover end
2017/08/04 00:33:21 [ux_dck_zpool_loop] INFO  - Master Failure detected! Retry 2/3
2017/08/04 00:33:21 [ux_dck_zpool_loop] TEST  - Waiting Failover end
2017/08/04 00:33:23 [ux_dck_zpool_loop] TEST  - Waiting Failover end
2017/08/04 00:33:24 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/04 00:33:25 [ux_dck_zpool_loop] TEST  - Waiting Failover end
2017/08/04 00:33:26 [ux_dck_zpool_loop] INFO  - Master Failure detected! Retry 3/3
2017/08/04 00:33:26 [ux_dck_zpool_loop] INFO  - Declaring master as failed
2017/08/04 00:33:26 [ux_dck_zpool_loop] ALERT - Server 192.168.100.70 state changed from Suspect to Failed
2017/08/04 00:33:27 [ux_dck_zpool_loop] TEST  - Waiting Failover end
2017/08/04 00:33:29 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/04 00:33:29 [ux_dck_zpool_loop] STATE - ERR00033 Skip slave in election 192.168.100.71 have no master log file, slave might have failed
2017/08/04 00:33:29 [ux_dck_zpool_loop] STATE - ERR00032 No candidates found in slaves list
2017/08/04 00:33:29 [ux_dck_zpool_loop] STATE - WARN0023 Failover number of master pings failure has been reached
2017/08/04 00:33:29 [ux_dck_zpool_loop] STATE - ERR00036 Skip slave in election 192.168.100.72 is relay
2017/08/04 00:33:29 [ux_dck_zpool_loop] TEST  - Waiting Failover end
2017/08/04 00:33:31 [ux_dck_zpool_loop] TEST  - Waiting Failover end
2017/08/04 00:33:33 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/04 00:33:33 [ux_dck_zpool_loop] TEST  - Waiting Failover end
2017/08/04 00:33:35 [ux_dck_zpool_loop] TEST  - Waiting Failover end
2017/08/04 00:33:37 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/04 00:33:37 [ux_dck_zpool_loop] TEST  - Waiting Failover end
2017/08/04 00:33:39 [ux_dck_zpool_loop] TEST  - Waiting Failover end
2017/08/04 00:33:41 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/04 00:33:41 [ux_dck_zpool_loop] TEST  - Waiting Failover end
2017/08/04 00:33:43 [ux_dck_zpool_loop] TEST  - Waiting Failover end
2017/08/04 00:33:45 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/04 00:33:45 [ux_dck_zpool_loop] TEST  - Waiting Failover end
2017/08/04 00:33:47 [ux_dck_zpool_loop] TEST  - Waiting Failover end
2017/08/04 00:33:49 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/04 00:33:49 [ux_dck_zpool_loop] TEST  - Waiting Failover end
2017/08/04 00:33:51 [ux_dck_zpool_loop] TEST  - Waiting Failover end
2017/08/04 00:33:53 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/04 00:33:53 [ux_dck_zpool_loop] TEST  - Waiting Failover end
2017/08/04 00:33:55 [ux_dck_zpool_loop] TEST  - Waiting Failover end
2017/08/04 00:33:57 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/04 00:33:57 [ux_dck_zpool_loop] TEST  - Waiting Failover end
2017/08/04 00:33:59 [ux_dck_zpool_loop] TEST  - Waiting Failover end
2017/08/04 00:34:01 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/04 00:34:01 [ux_dck_zpool_loop] TEST  - Waiting Failover end
2017/08/04 00:34:03 [ux_dck_zpool_loop] TEST  - Waiting Failover end
2017/08/04 00:34:05 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/04 00:34:05 [ux_dck_zpool_loop] TEST  - Waiting Failover end
2017/08/04 00:34:07 [ux_dck_zpool_loop] TEST  - Waiting Failover end
2017/08/04 00:34:09 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/04 00:34:09 [ux_dck_zpool_loop] TEST  - Waiting Failover end
2017/08/04 00:34:11 [ux_dck_zpool_loop] TEST  - Waiting Failover end
2017/08/04 00:34:13 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/04 00:34:13 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/04 00:34:13 [ux_dck_zpool_loop] TEST  - Waiting Failover end
2017/08/04 00:34:14 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/04 00:34:15 [ux_dck_zpool_loop] TEST  - Waiting Failover end
2017/08/04 00:34:15 [ux_dck_zpool_loop] TEST  - Failover end timeout
2017/08/04 00:34:15 [ux_dck_zpool_loop] TEST  -  Old master 192.168.100.70 ==  Next master 192.168.100.70  
2017/08/04 00:34:16 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/04 00:34:16 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/04 00:34:16 [ux_dck_zpool_loop] STATE - ERR00032 CLOSING No candidates found in slaves list
2017/08/04 00:34:16 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/04 00:34:16 [ux_dck_zpool_loop] STATE - WARN0051 CLOSING No GTID replication on slave 192.168.100.71
2017/08/04 00:34:16 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/04 00:34:16 [ux_dck_zpool_loop] STATE - ERR00033 CLOSING Skip slave in election 192.168.100.71 have no master log file, slave might have failed
2017/08/04 00:34:16 [ux_dck_zpool_loop] STATE - ERR00036 CLOSING Skip slave in election 192.168.100.72 is relay
2017/08/04 00:34:16 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/04 00:34:16 [ux_dck_zpool_loop] STATE - WARN0023 CLOSING Failover number of master pings failure has been reached
2017/08/04 00:34:16 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/04 00:34:18 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/04 00:34:18 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/04 00:34:18 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/04 00:34:18 [ux_dck_zpool_loop] STATE - WARN0023 CLOSING Failover number of master pings failure has been reached
2017/08/04 00:34:18 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/04 00:34:18 [ux_dck_zpool_loop] STATE - WARN0051 CLOSING No GTID replication on slave 192.168.100.71
2017/08/04 00:34:18 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/04 00:34:18 [ux_dck_zpool_loop] STATE - ERR00033 CLOSING Skip slave in election 192.168.100.71 have no master log file, slave might have failed
2017/08/04 00:34:18 [ux_dck_zpool_loop] STATE - ERR00036 CLOSING Skip slave in election 192.168.100.72 is relay
2017/08/04 00:34:18 [ux_dck_zpool_loop] STATE - ERR00032 CLOSING No candidates found in slaves list
2017/08/04 00:34:18 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/04 00:34:20 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/04 00:34:20 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/04 00:34:20 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/04 00:34:20 [ux_dck_zpool_loop] STATE - WARN0051 CLOSING No GTID replication on slave 192.168.100.71
2017/08/04 00:34:20 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/04 00:34:20 [ux_dck_zpool_loop] STATE - ERR00033 CLOSING Skip slave in election 192.168.100.71 have no master log file, slave might have failed
2017/08/04 00:34:20 [ux_dck_zpool_loop] STATE - ERR00036 CLOSING Skip slave in election 192.168.100.72 is relay
2017/08/04 00:34:20 [ux_dck_zpool_loop] STATE - ERR00032 CLOSING No candidates found in slaves list
2017/08/04 00:34:20 [ux_dck_zpool_loop] STATE - WARN0023 CLOSING Failover number of master pings failure has been reached
2017/08/04 00:34:20 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/04 00:34:20 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/04 00:34:20 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/04 00:34:22 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/04 00:34:22 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/04 00:34:22 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/04 00:34:22 [ux_dck_zpool_loop] STATE - WARN0051 CLOSING No GTID replication on slave 192.168.100.71
2017/08/04 00:34:22 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/04 00:34:22 [ux_dck_zpool_loop] STATE - ERR00033 CLOSING Skip slave in election 192.168.100.71 have no master log file, slave might have failed
2017/08/04 00:34:22 [ux_dck_zpool_loop] STATE - ERR00036 CLOSING Skip slave in election 192.168.100.72 is relay
2017/08/04 00:34:22 [ux_dck_zpool_loop] STATE - ERR00032 CLOSING No candidates found in slaves list
2017/08/04 00:34:22 [ux_dck_zpool_loop] STATE - WARN0023 CLOSING Failover number of master pings failure has been reached
2017/08/04 00:34:22 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/04 00:34:22 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/04 00:34:22 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/04 00:34:24 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/04 00:34:24 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/04 00:34:24 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/04 00:34:24 [ux_dck_zpool_loop] STATE - WARN0051 CLOSING No GTID replication on slave 192.168.100.71
2017/08/04 00:34:24 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/04 00:34:24 [ux_dck_zpool_loop] STATE - ERR00033 CLOSING Skip slave in election 192.168.100.71 have no master log file, slave might have failed
2017/08/04 00:34:24 [ux_dck_zpool_loop] STATE - ERR00036 CLOSING Skip slave in election 192.168.100.72 is relay
2017/08/04 00:34:24 [ux_dck_zpool_loop] STATE - ERR00032 CLOSING No candidates found in slaves list
2017/08/04 00:34:24 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/04 00:34:24 [ux_dck_zpool_loop] STATE - WARN0023 CLOSING Failover number of master pings failure has been reached
2017/08/04 00:34:24 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/04 00:34:24 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/04 00:34:27 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/04 00:34:27 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/04 00:34:27 [ux_dck_zpool_loop] STATE - WARN0023 CLOSING Failover number of master pings failure has been reached
2017/08/04 00:34:27 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/04 00:34:27 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/04 00:34:27 [ux_dck_zpool_loop] STATE - WARN0051 CLOSING No GTID replication on slave 192.168.100.71
2017/08/04 00:34:27 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/04 00:34:27 [ux_dck_zpool_loop] STATE - ERR00033 CLOSING Skip slave in election 192.168.100.71 have no master log file, slave might have failed
2017/08/04 00:34:27 [ux_dck_zpool_loop] STATE - ERR00036 CLOSING Skip slave in election 192.168.100.72 is relay
2017/08/04 00:34:27 [ux_dck_zpool_loop] STATE - ERR00032 CLOSING No candidates found in slaves list
2017/08/04 00:34:27 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/04 00:34:27 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/04 00:34:29 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/04 00:34:29 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/04 00:34:29 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/04 00:34:29 [ux_dck_zpool_loop] STATE - WARN0051 CLOSING No GTID replication on slave 192.168.100.71
2017/08/04 00:34:29 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/04 00:34:29 [ux_dck_zpool_loop] STATE - ERR00033 CLOSING Skip slave in election 192.168.100.71 have no master log file, slave might have failed
2017/08/04 00:34:29 [ux_dck_zpool_loop] STATE - ERR00036 CLOSING Skip slave in election 192.168.100.72 is relay
2017/08/04 00:34:29 [ux_dck_zpool_loop] STATE - ERR00032 CLOSING No candidates found in slaves list
2017/08/04 00:34:29 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/04 00:34:29 [ux_dck_zpool_loop] STATE - WARN0023 CLOSING Failover number of master pings failure has been reached
2017/08/04 00:34:29 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/04 00:34:29 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/04 00:34:31 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/04 00:34:31 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/04 00:34:31 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/04 00:34:31 [ux_dck_zpool_loop] STATE - ERR00033 CLOSING Skip slave in election 192.168.100.71 have no master log file, slave might have failed
2017/08/04 00:34:31 [ux_dck_zpool_loop] STATE - ERR00036 CLOSING Skip slave in election 192.168.100.72 is relay
2017/08/04 00:34:31 [ux_dck_zpool_loop] STATE - ERR00032 CLOSING No candidates found in slaves list
2017/08/04 00:34:31 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/04 00:34:31 [ux_dck_zpool_loop] STATE - WARN0051 CLOSING No GTID replication on slave 192.168.100.71
2017/08/04 00:34:31 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/04 00:34:31 [ux_dck_zpool_loop] STATE - WARN0023 CLOSING Failover number of master pings failure has been reached
2017/08/04 00:34:31 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/04 00:34:31 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/04 00:34:33 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/04 00:34:33 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/04 00:34:33 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/04 00:34:33 [ux_dck_zpool_loop] STATE - ERR00033 CLOSING Skip slave in election 192.168.100.71 have no master log file, slave might have failed
2017/08/04 00:34:33 [ux_dck_zpool_loop] STATE - ERR00036 CLOSING Skip slave in election 192.168.100.72 is relay
2017/08/04 00:34:33 [ux_dck_zpool_loop] STATE - ERR00032 CLOSING No candidates found in slaves list
2017/08/04 00:34:33 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/04 00:34:33 [ux_dck_zpool_loop] STATE - WARN0051 CLOSING No GTID replication on slave 192.168.100.71
2017/08/04 00:34:33 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/04 00:34:33 [ux_dck_zpool_loop] STATE - WARN0023 CLOSING Failover number of master pings failure has been reached
2017/08/04 00:34:33 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/04 00:34:33 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/04 00:34:35 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/04 00:34:35 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/04 00:34:35 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/04 00:34:35 [ux_dck_zpool_loop] STATE - WARN0023 CLOSING Failover number of master pings failure has been reached
2017/08/04 00:34:35 [ux_dck_zpool_loop] STATE - WARN0051 CLOSING No GTID replication on slave 192.168.100.71
2017/08/04 00:34:35 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/04 00:34:35 [ux_dck_zpool_loop] STATE - ERR00033 CLOSING Skip slave in election 192.168.100.71 have no master log file, slave might have failed
2017/08/04 00:34:35 [ux_dck_zpool_loop] STATE - ERR00036 CLOSING Skip slave in election 192.168.100.72 is relay
2017/08/04 00:34:35 [ux_dck_zpool_loop] STATE - ERR00032 CLOSING No candidates found in slaves list
2017/08/04 00:34:35 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/04 00:34:35 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/04 00:34:35 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/04 00:34:37 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/04 00:34:37 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/04 00:34:37 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/04 00:34:37 [ux_dck_zpool_loop] STATE - WARN0051 CLOSING No GTID replication on slave 192.168.100.71
2017/08/04 00:34:37 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/04 00:34:37 [ux_dck_zpool_loop] STATE - ERR00033 CLOSING Skip slave in election 192.168.100.71 have no master log file, slave might have failed
2017/08/04 00:34:37 [ux_dck_zpool_loop] STATE - ERR00036 CLOSING Skip slave in election 192.168.100.72 is relay
2017/08/04 00:34:37 [ux_dck_zpool_loop] STATE - ERR00032 CLOSING No candidates found in slaves list
2017/08/04 00:34:37 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/04 00:34:37 [ux_dck_zpool_loop] STATE - WARN0023 CLOSING Failover number of master pings failure has been reached
2017/08/04 00:34:37 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/04 00:34:37 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/04 00:34:39 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/04 00:34:48 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/04 00:34:48 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/04 00:34:48 [ux_dck_zpool_loop] STATE - WARN0051 CLOSING No GTID replication on slave 192.168.100.71
2017/08/04 00:34:48 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/04 00:34:48 [ux_dck_zpool_loop] STATE - ERR00033 CLOSING Skip slave in election 192.168.100.71 have no master log file, slave might have failed
2017/08/04 00:34:48 [ux_dck_zpool_loop] STATE - ERR00036 CLOSING Skip slave in election 192.168.100.72 is relay
2017/08/04 00:34:48 [ux_dck_zpool_loop] STATE - ERR00032 CLOSING No candidates found in slaves list
2017/08/04 00:34:48 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/04 00:34:48 [ux_dck_zpool_loop] STATE - WARN0023 CLOSING Failover number of master pings failure has been reached
2017/08/04 00:34:48 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/04 00:34:48 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/04 00:34:48 [ux_dck_zpool_loop] ERROR - dial tcp 192.168.100.50:4007: getsockopt: connection refused
2017/08/04 00:34:49 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/04 00:34:50 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/04 00:34:50 [ux_dck_zpool_loop] STATE - WARN0051 CLOSING No GTID replication on slave 192.168.100.71
2017/08/04 00:34:50 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/04 00:34:50 [ux_dck_zpool_loop] STATE - ERR00033 CLOSING Skip slave in election 192.168.100.71 have no master log file, slave might have failed
2017/08/04 00:34:50 [ux_dck_zpool_loop] STATE - ERR00036 CLOSING Skip slave in election 192.168.100.72 is relay
2017/08/04 00:34:50 [ux_dck_zpool_loop] STATE - ERR00032 CLOSING No candidates found in slaves list
2017/08/04 00:34:50 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/04 00:34:50 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/04 00:34:50 [ux_dck_zpool_loop] STATE - WARN0023 CLOSING Failover number of master pings failure has been reached
2017/08/04 00:34:50 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/04 00:34:50 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/04 00:34:51 [ux_dck_zpool_loop] ERROR - dial tcp 192.168.100.50:4007: i/o timeout
2017/08/04 00:34:51 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/04 00:34:52 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/04 00:34:52 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/04 00:34:52 [ux_dck_zpool_loop] STATE - WARN0051 CLOSING No GTID replication on slave 192.168.100.71
2017/08/04 00:34:52 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/04 00:34:52 [ux_dck_zpool_loop] STATE - ERR00033 CLOSING Skip slave in election 192.168.100.71 have no master log file, slave might have failed
2017/08/04 00:34:52 [ux_dck_zpool_loop] STATE - ERR00036 CLOSING Skip slave in election 192.168.100.72 is relay
2017/08/04 00:34:52 [ux_dck_zpool_loop] STATE - ERR00032 CLOSING No candidates found in slaves list
2017/08/04 00:34:52 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/04 00:34:52 [ux_dck_zpool_loop] STATE - WARN0023 CLOSING Failover number of master pings failure has been reached
2017/08/04 00:34:52 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/04 00:34:52 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/04 00:34:53 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/04 00:34:53 [ux_dck_zpool_loop] ERROR - dial tcp 192.168.100.50:4007: i/o timeout
2017/08/04 00:34:54 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/04 00:34:54 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/04 00:34:54 [ux_dck_zpool_loop] STATE - WARN0051 CLOSING No GTID replication on slave 192.168.100.71
2017/08/04 00:34:54 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/04 00:34:54 [ux_dck_zpool_loop] STATE - ERR00033 CLOSING Skip slave in election 192.168.100.71 have no master log file, slave might have failed
2017/08/04 00:34:54 [ux_dck_zpool_loop] STATE - ERR00036 CLOSING Skip slave in election 192.168.100.72 is relay
2017/08/04 00:34:54 [ux_dck_zpool_loop] STATE - ERR00032 CLOSING No candidates found in slaves list
2017/08/04 00:34:54 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/04 00:34:54 [ux_dck_zpool_loop] STATE - WARN0023 CLOSING Failover number of master pings failure has been reached
2017/08/04 00:34:54 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/04 00:34:54 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/04 00:34:55 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/04 00:34:55 [ux_dck_zpool_loop] ERROR - dial tcp 192.168.100.50:4007: i/o timeout
2017/08/04 00:34:56 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/04 00:34:56 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/04 00:34:56 [ux_dck_zpool_loop] STATE - WARN0051 CLOSING No GTID replication on slave 192.168.100.71
2017/08/04 00:34:56 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/04 00:34:56 [ux_dck_zpool_loop] STATE - ERR00033 CLOSING Skip slave in election 192.168.100.71 have no master log file, slave might have failed
2017/08/04 00:34:56 [ux_dck_zpool_loop] STATE - ERR00036 CLOSING Skip slave in election 192.168.100.72 is relay
2017/08/04 00:34:56 [ux_dck_zpool_loop] STATE - ERR00032 CLOSING No candidates found in slaves list
2017/08/04 00:34:56 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/04 00:34:56 [ux_dck_zpool_loop] STATE - WARN0023 CLOSING Failover number of master pings failure has been reached
2017/08/04 00:34:56 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/04 00:34:56 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/04 00:34:57 [ux_dck_zpool_loop] ERROR - dial tcp 192.168.100.50:4007: i/o timeout
2017/08/04 00:34:57 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/04 00:34:58 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/04 00:34:58 [ux_dck_zpool_loop] STATE - ERR00032 CLOSING No candidates found in slaves list
2017/08/04 00:34:58 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/04 00:34:58 [ux_dck_zpool_loop] STATE - WARN0051 CLOSING No GTID replication on slave 192.168.100.71
2017/08/04 00:34:58 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/04 00:34:58 [ux_dck_zpool_loop] STATE - ERR00033 CLOSING Skip slave in election 192.168.100.71 have no master log file, slave might have failed
2017/08/04 00:34:58 [ux_dck_zpool_loop] STATE - ERR00036 CLOSING Skip slave in election 192.168.100.72 is relay
2017/08/04 00:34:58 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/04 00:34:58 [ux_dck_zpool_loop] STATE - WARN0023 CLOSING Failover number of master pings failure has been reached
2017/08/04 00:34:58 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/04 00:34:58 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/04 00:34:59 [ux_dck_zpool_loop] ERROR - dial tcp 192.168.100.50:4007: i/o timeout
2017/08/04 00:34:59 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/04 00:35:00 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/04 00:35:00 [ux_dck_zpool_loop] STATE - ERR00036 CLOSING Skip slave in election 192.168.100.72 is relay
2017/08/04 00:35:00 [ux_dck_zpool_loop] STATE - ERR00032 CLOSING No candidates found in slaves list
2017/08/04 00:35:00 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/04 00:35:00 [ux_dck_zpool_loop] STATE - WARN0051 CLOSING No GTID replication on slave 192.168.100.71
2017/08/04 00:35:00 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/04 00:35:00 [ux_dck_zpool_loop] STATE - ERR00033 CLOSING Skip slave in election 192.168.100.71 have no master log file, slave might have failed
2017/08/04 00:35:00 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/04 00:35:00 [ux_dck_zpool_loop] STATE - WARN0023 CLOSING Failover number of master pings failure has been reached
2017/08/04 00:35:00 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/04 00:35:00 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/04 00:35:00 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/04 00:35:01 [ux_dck_zpool_loop] ERROR - dial tcp 192.168.100.50:4007: i/o timeout
2017/08/04 00:35:01 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/04 00:35:01 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/04 00:35:01 [ux_dck_zpool_loop] STATE - WARN0051 CLOSING No GTID replication on slave 192.168.100.71
2017/08/04 00:35:01 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/04 00:35:01 [ux_dck_zpool_loop] STATE - ERR00033 CLOSING Skip slave in election 192.168.100.71 have no master log file, slave might have failed
2017/08/04 00:35:01 [ux_dck_zpool_loop] STATE - ERR00036 CLOSING Skip slave in election 192.168.100.72 is relay
2017/08/04 00:35:01 [ux_dck_zpool_loop] STATE - ERR00032 CLOSING No candidates found in slaves list
2017/08/04 00:35:01 [ux_dck_zpool_loop] STATE - WARN0023 CLOSING Failover number of master pings failure has been reached
2017/08/04 00:35:01 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/04 00:35:01 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/04 00:35:01 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/04 00:35:01 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/04 00:35:02 [ux_dck_zpool_loop] ERROR - dial tcp 192.168.100.50:4007: i/o timeout
2017/08/04 00:35:02 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/04 00:35:02 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/04 00:35:02 [ux_dck_zpool_loop] STATE - WARN0023 CLOSING Failover number of master pings failure has been reached
2017/08/04 00:35:02 [ux_dck_zpool_loop] STATE - WARN0051 CLOSING No GTID replication on slave 192.168.100.71
2017/08/04 00:35:02 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/04 00:35:02 [ux_dck_zpool_loop] STATE - ERR00033 CLOSING Skip slave in election 192.168.100.71 have no master log file, slave might have failed
2017/08/04 00:35:02 [ux_dck_zpool_loop] STATE - ERR00036 CLOSING Skip slave in election 192.168.100.72 is relay
2017/08/04 00:35:02 [ux_dck_zpool_loop] STATE - ERR00032 CLOSING No candidates found in slaves list
2017/08/04 00:35:02 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/04 00:35:02 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/04 00:35:02 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/04 00:35:02 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/04 00:35:03 [ux_dck_zpool_loop] ERROR - dial tcp 192.168.100.50:4007: i/o timeout
2017/08/04 00:35:03 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/04 00:35:03 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/04 00:35:03 [ux_dck_zpool_loop] STATE - WARN0023 CLOSING Failover number of master pings failure has been reached
2017/08/04 00:35:03 [ux_dck_zpool_loop] STATE - ERR00033 CLOSING Skip slave in election 192.168.100.71 have no master log file, slave might have failed
2017/08/04 00:35:03 [ux_dck_zpool_loop] STATE - ERR00036 CLOSING Skip slave in election 192.168.100.72 is relay
2017/08/04 00:35:03 [ux_dck_zpool_loop] STATE - ERR00032 CLOSING No candidates found in slaves list
2017/08/04 00:35:03 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/04 00:35:03 [ux_dck_zpool_loop] STATE - WARN0051 CLOSING No GTID replication on slave 192.168.100.71
2017/08/04 00:35:03 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/04 00:35:03 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/04 00:35:03 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/04 00:35:04 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/04 00:35:04 [ux_dck_zpool_loop] ERROR - dial tcp 192.168.100.50:4007: i/o timeout
2017/08/04 00:35:05 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/04 00:35:05 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/04 00:35:05 [ux_dck_zpool_loop] STATE - WARN0023 CLOSING Failover number of master pings failure has been reached
2017/08/04 00:35:05 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/04 00:35:05 [ux_dck_zpool_loop] STATE - WARN0051 CLOSING No GTID replication on slave 192.168.100.71
2017/08/04 00:35:05 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/04 00:35:05 [ux_dck_zpool_loop] STATE - ERR00033 CLOSING Skip slave in election 192.168.100.71 have no master log file, slave might have failed
2017/08/04 00:35:05 [ux_dck_zpool_loop] STATE - ERR00036 CLOSING Skip slave in election 192.168.100.72 is relay
2017/08/04 00:35:05 [ux_dck_zpool_loop] STATE - ERR00032 CLOSING No candidates found in slaves list
2017/08/04 00:35:05 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/04 00:35:05 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/04 00:35:06 [ux_dck_zpool_loop] ERROR - dial tcp 192.168.100.50:4007: i/o timeout
2017/08/04 00:35:07 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/04 00:35:08 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/04 00:35:08 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/04 00:35:08 [ux_dck_zpool_loop] STATE - WARN0023 CLOSING Failover number of master pings failure has been reached
2017/08/04 00:35:08 [ux_dck_zpool_loop] STATE - ERR00032 CLOSING No candidates found in slaves list
2017/08/04 00:35:08 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/04 00:35:08 [ux_dck_zpool_loop] STATE - WARN0051 CLOSING No GTID replication on slave 192.168.100.71
2017/08/04 00:35:08 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/04 00:35:08 [ux_dck_zpool_loop] STATE - ERR00033 CLOSING Skip slave in election 192.168.100.71 have no master log file, slave might have failed
2017/08/04 00:35:08 [ux_dck_zpool_loop] STATE - ERR00036 CLOSING Skip slave in election 192.168.100.72 is relay
2017/08/04 00:35:08 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/04 00:35:08 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/04 00:35:09 [ux_dck_zpool_loop] ERROR - dial tcp 192.168.100.50:4007: i/o timeout
2017/08/04 00:35:09 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/04 00:35:10 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/04 00:35:10 [ux_dck_zpool_loop] STATE - WARN0051 CLOSING No GTID replication on slave 192.168.100.71
2017/08/04 00:35:10 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/04 00:35:10 [ux_dck_zpool_loop] STATE - ERR00033 CLOSING Skip slave in election 192.168.100.71 have no master log file, slave might have failed
2017/08/04 00:35:10 [ux_dck_zpool_loop] STATE - ERR00036 CLOSING Skip slave in election 192.168.100.72 is relay
2017/08/04 00:35:10 [ux_dck_zpool_loop] STATE - ERR00032 CLOSING No candidates found in slaves list
2017/08/04 00:35:10 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/04 00:35:10 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/04 00:35:10 [ux_dck_zpool_loop] STATE - WARN0023 CLOSING Failover number of master pings failure has been reached
2017/08/04 00:35:10 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/04 00:35:10 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/04 00:35:11 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/04 00:35:11 [ux_dck_zpool_loop] ERROR - dial tcp 192.168.100.50:4007: i/o timeout
2017/08/04 00:35:12 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/04 00:35:12 [ux_dck_zpool_loop] STATE - WARN0023 CLOSING Failover number of master pings failure has been reached
2017/08/04 00:35:12 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/04 00:35:12 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/04 00:35:12 [ux_dck_zpool_loop] STATE - WARN0051 CLOSING No GTID replication on slave 192.168.100.71
2017/08/04 00:35:12 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/04 00:35:12 [ux_dck_zpool_loop] STATE - ERR00033 CLOSING Skip slave in election 192.168.100.71 have no master log file, slave might have failed
2017/08/04 00:35:12 [ux_dck_zpool_loop] STATE - ERR00036 CLOSING Skip slave in election 192.168.100.72 is relay
2017/08/04 00:35:12 [ux_dck_zpool_loop] STATE - ERR00032 CLOSING No candidates found in slaves list
2017/08/04 00:35:12 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/04 00:35:12 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/04 00:35:13 [ux_dck_zpool_loop] ERROR - dial tcp 192.168.100.50:4007: i/o timeout
2017/08/04 00:35:13 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/04 00:35:14 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/04 00:35:14 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/04 00:35:14 [ux_dck_zpool_loop] STATE - WARN0051 CLOSING No GTID replication on slave 192.168.100.71
2017/08/04 00:35:14 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/04 00:35:14 [ux_dck_zpool_loop] STATE - ERR00033 CLOSING Skip slave in election 192.168.100.71 have no master log file, slave might have failed
2017/08/04 00:35:14 [ux_dck_zpool_loop] STATE - ERR00036 CLOSING Skip slave in election 192.168.100.72 is relay
2017/08/04 00:35:14 [ux_dck_zpool_loop] STATE - ERR00032 CLOSING No candidates found in slaves list
2017/08/04 00:35:14 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/04 00:35:14 [ux_dck_zpool_loop] STATE - WARN0023 CLOSING Failover number of master pings failure has been reached
2017/08/04 00:35:14 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/04 00:35:14 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/04 00:35:15 [ux_dck_zpool_loop] ERROR - dial tcp 192.168.100.50:4007: i/o timeout
2017/08/04 00:35:15 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/04 00:35:16 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/04 00:35:16 [ux_dck_zpool_loop] STATE - WARN0023 CLOSING Failover number of master pings failure has been reached
2017/08/04 00:35:16 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/04 00:35:16 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/04 00:35:16 [ux_dck_zpool_loop] STATE - WARN0051 CLOSING No GTID replication on slave 192.168.100.71
2017/08/04 00:35:16 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/04 00:35:16 [ux_dck_zpool_loop] STATE - ERR00033 CLOSING Skip slave in election 192.168.100.71 have no master log file, slave might have failed
2017/08/04 00:35:16 [ux_dck_zpool_loop] STATE - ERR00036 CLOSING Skip slave in election 192.168.100.72 is relay
2017/08/04 00:35:16 [ux_dck_zpool_loop] STATE - ERR00032 CLOSING No candidates found in slaves list
2017/08/04 00:35:16 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/04 00:35:16 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/04 00:35:17 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/04 00:35:17 [ux_dck_zpool_loop] ERROR - dial tcp 192.168.100.50:4007: i/o timeout
2017/08/04 00:35:18 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/04 00:35:18 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/04 00:35:18 [ux_dck_zpool_loop] STATE - WARN0023 CLOSING Failover number of master pings failure has been reached
2017/08/04 00:35:18 [ux_dck_zpool_loop] STATE - ERR00032 CLOSING No candidates found in slaves list
2017/08/04 00:35:18 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/04 00:35:18 [ux_dck_zpool_loop] STATE - WARN0051 CLOSING No GTID replication on slave 192.168.100.71
2017/08/04 00:35:18 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/04 00:35:18 [ux_dck_zpool_loop] STATE - ERR00033 CLOSING Skip slave in election 192.168.100.71 have no master log file, slave might have failed
2017/08/04 00:35:18 [ux_dck_zpool_loop] STATE - ERR00036 CLOSING Skip slave in election 192.168.100.72 is relay
2017/08/04 00:35:18 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/04 00:35:19 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/04 00:35:20 [ux_dck_zpool_loop] ERROR - dial tcp 192.168.100.50:4007: i/o timeout
2017/08/04 00:35:20 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/04 00:35:21 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/04 00:35:21 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/04 00:35:21 [ux_dck_zpool_loop] STATE - WARN0023 CLOSING Failover number of master pings failure has been reached
2017/08/04 00:35:21 [ux_dck_zpool_loop] STATE - ERR00036 CLOSING Skip slave in election 192.168.100.72 is relay
2017/08/04 00:35:21 [ux_dck_zpool_loop] STATE - ERR00032 CLOSING No candidates found in slaves list
2017/08/04 00:35:21 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/04 00:35:21 [ux_dck_zpool_loop] STATE - WARN0051 CLOSING No GTID replication on slave 192.168.100.71
2017/08/04 00:35:21 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/04 00:35:21 [ux_dck_zpool_loop] STATE - ERR00033 CLOSING Skip slave in election 192.168.100.71 have no master log file, slave might have failed
2017/08/04 00:35:21 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/04 00:35:21 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/04 00:35:21 [ux_dck_zpool_loop] INFO  - hostlist: 192.168.100.70,192.168.100.71,192.168.100.72 [192.168.100.70 192.168.100.71 192.168.100.72]
2017/08/04 00:35:21 [ux_dck_zpool_loop] INFO  - Loading 1 proxies
2017/08/04 00:35:21 [ux_dck_zpool_loop] INFO  - Loading Maxscale...
2017/08/04 00:35:21 [ux_dck_zpool_loop] TEST  - Result FailoverAssyncAutoRejoinNoGtid                           -> {testFailoverAssyncAutoRejoinNoGtid FAIL ././config/masterslave/mariadb/with_traffic/10.2/x3/multidomains/innodb/maxscale/latest/x1/replication-manager.conf {/var/lib/replication-manager /usr/local/share/mrm root:mariadb 192.168.100.70,192.168.100.71,192.168.100.72     root:mariadb %!s(bool=false) %!s(bool=false)    192.168.100.70  %!s(int64=5000) %!s(int64=10) %!s(int=10) %!s(bool=false) %!s(bool=false) %!s(int64=0) %!s(bool=true) %!s(bool=true) %!s(bool=true) %!s(bool=true) %!s(bool=true) %!s(bool=true) ./config/masterslave/mariadb/with_traffic/10.2/x3/multidomains/innodb/maxscale/latest/x1/1.1.0-preview3-98-gc4fd436/testFailoverAssyncAutoRejoinNoGtid.log %!s(int64=2) %!s(int=1) tcp %!s(bool=true) %!s(bool=true) %!s(bool=false) %!s(int=3) %!s(int=5) %!s(bool=false) %!s(bool=true) %!s(bool=true) %!s(bool=true) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(uint64=1000000000) %!s(bool=true) %!s(bool=true) %!s(bool=false) %!s(bool=true)  %!s(bool=false) %!s(bool=false) %!s(bool=false) localhost 10001 %!s(bool=true) ../../dashboard %!s(bool=false) %!s(bool=true) %!s(int=3600) %!s(bool=true) mrm@localhost  localhost:25 %!s(int=10) %!s(int=999) %!s(int64=1) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(int=3) %!s(int64=300) %!s(int64=0) %!s(bool=false) %!s(bool=false) %!s(int=3) %!s(int=14) %!s(bool=false) %!s(int=80) %!s(bool=false) %!s(bool=false) 127.0.0.1:3307 admin %!s(bool=true) 192.168.100.50 3307 admin mariadb %!s(int=4007) %!s(int=4008) %!s(int=4006) %!s(int=3307) %!s(bool=false) %!s(int=3309) %!s(bool=false) maxadmin %!s(bool=false) %!s(bool=false) %!s(int=3306) %!s(int=3307) %!s(int=1988) 0.0.0.0 0.0.0.0 /usr/sbin/haproxy /etc/replication-manager/.replication-manager.key %!s(int=0) %!s(bool=true) %!s(bool=true) unknown %!s(bool=false) %!s(bool=false) 127.0.0.1 %!s(int=2003) %!s(int=10002) %!s(int=10003) %!s(int=7002) %!s(int=2004) %!s(int=7007) /usr/local/bin/sysbench %!s(int=60) %!s(int=4) /usr/local/mysql/bin %!s(bool=false)  88.191.151.84:80 %!s(int=0) 127.0.0.1:10002 %!s(bool=false) %!s(bool=true) %!s(bool=false) %!s(bool=true) 192.168.100.101:443 root@localhost.localdomain:opensvc replication-manager@localhost.localdomain:mariadb docker node-1-1.vdc.opensvc.com,node-1-2.vdc.opensvc.com 256 300 smallredolog,semisync,innodb,noquerycache,threadpool,logslow,multidomains 1G zfs zpool /srv loopback br0 255.255.255.0 192.168.100.254 docker node-1-2.vdc.opensvc.com 1G zfs zpool /srv loopback br0 255.255.255.0 192.168.100.254     mariadb:10.2 asosso/maxscale:latest admin:mariadb 3000 ././config/masterslave/mariadb/with_traffic/10.2/x3/multidomains/innodb/maxscale/latest/x1/replication-manager.conf} {/var/lib/replication-manager /usr/local/share/mrm root:mariadb 192.168.100.70,192.168.100.71,192.168.100.72     root:mariadb %!s(bool=false) %!s(bool=false)    192.168.100.70  %!s(int64=5000) %!s(int64=10) %!s(int=10) %!s(bool=false) %!s(bool=false) %!s(int64=0) %!s(bool=true) %!s(bool=true) %!s(bool=true) %!s(bool=true) %!s(bool=true) %!s(bool=true) ./config/masterslave/mariadb/with_traffic/10.2/x3/multidomains/innodb/maxscale/latest/x1/1.1.0-preview3-98-gc4fd436/testFailoverAssyncAutoRejoinNoGtid.log %!s(int64=2) %!s(int=1) tcp %!s(bool=true) %!s(bool=true) %!s(bool=false) %!s(int=3) %!s(int=5) %!s(bool=false) %!s(bool=true) %!s(bool=true) %!s(bool=true) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(uint64=1000000000) %!s(bool=true) %!s(bool=true) %!s(bool=false) %!s(bool=false)  %!s(bool=false) %!s(bool=false) %!s(bool=false) localhost 10001 %!s(bool=true) ../../dashboard %!s(bool=false) %!s(bool=true) %!s(int=3600) %!s(bool=true) mrm@localhost  localhost:25 %!s(int=10) %!s(int=999) %!s(int64=1) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(int=3) %!s(int64=300) %!s(int64=0) %!s(bool=false) %!s(bool=false) %!s(int=3) %!s(int=14) %!s(bool=false) %!s(int=80) %!s(bool=false) %!s(bool=false) 127.0.0.1:3307 admin %!s(bool=true) 192.168.100.50 3307 admin mariadb %!s(int=4007) %!s(int=4008) %!s(int=4006) %!s(int=3307) %!s(bool=false) %!s(int=3309) %!s(bool=false) maxadmin %!s(bool=false) %!s(bool=false) %!s(int=3306) %!s(int=3307) %!s(int=1988) 0.0.0.0 0.0.0.0 /usr/sbin/haproxy /etc/replication-manager/.replication-manager.key %!s(int=0) %!s(bool=true) %!s(bool=true) multi-tier-slave %!s(bool=false) %!s(bool=false) 127.0.0.1 %!s(int=2003) %!s(int=10002) %!s(int=10003) %!s(int=7002) %!s(int=2004) %!s(int=7007) /usr/local/bin/sysbench %!s(int=60) %!s(int=4) /usr/local/mysql/bin %!s(bool=false)  88.191.151.84:80 %!s(int=0) 127.0.0.1:10002 %!s(bool=false) %!s(bool=true) %!s(bool=false) %!s(bool=true) 192.168.100.101:443 root@localhost.localdomain:opensvc replication-manager@localhost.localdomain:mariadb docker node-1-1.vdc.opensvc.com,node-1-2.vdc.opensvc.com 256 300 smallredolog,semisync,innodb,noquerycache,threadpool,logslow,multidomains 1G zfs zpool /srv loopback br0 255.255.255.0 192.168.100.254 docker node-1-2.vdc.opensvc.com 1G zfs zpool /srv loopback br0 255.255.255.0 192.168.100.254     mariadb:10.2 asosso/maxscale:latest admin:mariadb 3000 ././config/masterslave/mariadb/with_traffic/10.2/x3/multidomains/innodb/maxscale/latest/x1/replication-manager.conf}}
