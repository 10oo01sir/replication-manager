2017/08/03 14:48:46 [ux_dck_zpool_loop] INFO  - hostlist: 192.168.100.70,192.168.100.71 [192.168.100.70 192.168.100.71]
2017/08/03 14:48:46 [ux_dck_zpool_loop] INFO  - Loading 1 proxies
2017/08/03 14:48:46 [ux_dck_zpool_loop] INFO  - Loading Maxscale...
2017/08/03 14:48:46 [ux_dck_zpool_loop] INFO  - Failover in automatic mode
2017/08/03 14:48:46 [ux_dck_zpool_loop] ERROR - File error: open /var/lib/replication-manager/ux_dck_zpool_loop.json: no such file or directory

2017/08/03 14:48:48 [ux_dck_zpool_loop] ALERT - Server 192.168.100.70 state changed from  to Suspect
2017/08/03 14:48:48 [ux_dck_zpool_loop] TESTI - testFailoverSemisyncAutoRejoinSafeMSMXXXRXSMS
2017/08/03 14:48:49 [ux_dck_zpool_loop] ALERT - Server 192.168.100.71 state changed from  to Suspect
2017/08/03 14:48:50 [ux_dck_zpool_loop] INFO  - Provisioning delete service dd9a5909-a7f2-4793-9cd1-c5c40a016999
2017/08/03 14:48:53 [ux_dck_zpool_loop] STATE - ERR00012 Could not find a master in topology
2017/08/03 14:48:53 [ux_dck_zpool_loop] STATE - ERR00021 All cluster down in non-interactive mode
2017/08/03 14:48:53 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/03 14:48:53 [ux_dck_zpool_loop] STATE - ERR00010 Could not find a slave in topology
2017/08/03 14:48:58 [ux_dck_zpool_loop] STATE - ERR0046 Provision task is in queue
2017/08/03 14:48:59 [ux_dck_zpool_loop] INFO  - Declaring server 192.168.100.71 as failed
2017/08/03 14:48:59 [ux_dck_zpool_loop] ALERT - Server 192.168.100.71 state changed from Suspect to Failed
2017/08/03 14:48:59 [ux_dck_zpool_loop] INFO  - Declaring server 192.168.100.70 as failed
2017/08/03 14:48:59 [ux_dck_zpool_loop] ALERT - Server 192.168.100.70 state changed from Suspect to Failed
2017/08/03 14:49:07 [ux_dck_zpool_loop] STATE - ERR0046 CLOSING Provision task is in queue
2017/08/03 14:49:08 [ux_dck_zpool_loop] STATE - ERR0046 Provision task is in queue
2017/08/03 14:49:12 [ux_dck_zpool_loop] STATE - ERR0046 CLOSING Provision task is in queue
2017/08/03 14:49:14 [ux_dck_zpool_loop] STATE - ERR0046 Provision task is in queue
2017/08/03 14:49:40 [ux_dck_zpool_loop] STATE - ERR0046 CLOSING Provision task is in queue
2017/08/03 14:49:42 [ux_dck_zpool_loop] STATE - ERR0046 Provision task is in queue
2017/08/03 14:49:52 [ux_dck_zpool_loop] STATE - ERR0046 CLOSING Provision task is in queue
2017/08/03 14:49:54 [ux_dck_zpool_loop] STATE - ERR0046 Provision task is in queue
2017/08/03 14:50:11 [ux_dck_zpool_loop] STATE - ERR0046 CLOSING Provision task is in queue
2017/08/03 14:50:12 [ux_dck_zpool_loop] STATE - ERR0046 Provision task is in queue
2017/08/03 14:50:14 [ux_dck_zpool_loop] STATE - ERR0046 CLOSING Provision task is in queue
2017/08/03 14:50:16 [ux_dck_zpool_loop] STATE - ERR0046 Provision task is in queue
2017/08/03 14:50:44 [ux_dck_zpool_loop] STATE - ERR0046 CLOSING Provision task is in queue
2017/08/03 14:50:46 [ux_dck_zpool_loop] STATE - ERR0046 Provision task is in queue
2017/08/03 14:50:54 [ux_dck_zpool_loop] STATE - ERR0046 CLOSING Provision task is in queue
2017/08/03 14:50:56 [ux_dck_zpool_loop] STATE - ERR0046 Provision task is in queue
2017/08/03 14:51:15 [ux_dck_zpool_loop] STATE - ERR0046 CLOSING Provision task is in queue
2017/08/03 14:51:18 [ux_dck_zpool_loop] STATE - ERR0046 Provision task is in queue
2017/08/03 14:51:52 [ux_dck_zpool_loop] STATE - ERR0046 CLOSING Provision task is in queue
2017/08/03 14:51:54 [ux_dck_zpool_loop] STATE - ERR0046 Provision task is in queue
2017/08/03 14:51:56 [ux_dck_zpool_loop] STATE - ERR0046 CLOSING Provision task is in queue
2017/08/03 14:51:58 [ux_dck_zpool_loop] STATE - ERR0046 Provision task is in queue
2017/08/03 14:52:25 [ux_dck_zpool_loop] STATE - ERR0046 CLOSING Provision task is in queue
2017/08/03 14:52:28 [ux_dck_zpool_loop] STATE - ERR0046 Provision task is in queue
2017/08/03 14:52:36 [ux_dck_zpool_loop] STATE - ERR0046 CLOSING Provision task is in queue
2017/08/03 14:52:38 [ux_dck_zpool_loop] STATE - ERR0046 Provision task is in queue
2017/08/03 14:52:58 [ux_dck_zpool_loop] STATE - ERR0046 CLOSING Provision task is in queue
2017/08/03 14:53:00 [ux_dck_zpool_loop] STATE - ERR0046 Provision task is in queue
2017/08/03 14:53:31 [ux_dck_zpool_loop] STATE - ERR0046 CLOSING Provision task is in queue
2017/08/03 14:53:32 [ux_dck_zpool_loop] STATE - ERR0046 Provision task is in queue
2017/08/03 14:53:38 [ux_dck_zpool_loop] STATE - ERR0046 CLOSING Provision task is in queue
2017/08/03 14:53:40 [ux_dck_zpool_loop] STATE - ERR0046 Provision task is in queue
2017/08/03 14:54:02 [ux_dck_zpool_loop] STATE - ERR0046 CLOSING Provision task is in queue
2017/08/03 14:54:04 [ux_dck_zpool_loop] STATE - ERR0046 Provision task is in queue
2017/08/03 14:54:18 [ux_dck_zpool_loop] STATE - ERR0046 CLOSING Provision task is in queue
2017/08/03 14:54:25 [ux_dck_zpool_loop] STATE - ERR0046 Provision task is in queue
2017/08/03 14:54:34 [ux_dck_zpool_loop] STATE - ERR0046 CLOSING Provision task is in queue
2017/08/03 14:54:38 [ux_dck_zpool_loop] STATE - ERR0046 Provision task is in queue
2017/08/03 14:55:07 [ux_dck_zpool_loop] STATE - ERR0046 CLOSING Provision task is in queue
2017/08/03 14:55:08 [ux_dck_zpool_loop] STATE - ERR0046 Provision task is in queue
2017/08/03 14:55:18 [ux_dck_zpool_loop] STATE - ERR0046 CLOSING Provision task is in queue
2017/08/03 14:55:20 [ux_dck_zpool_loop] STATE - ERR0046 Provision task is in queue
2017/08/03 14:55:40 [ux_dck_zpool_loop] STATE - ERR0046 CLOSING Provision task is in queue
2017/08/03 14:55:42 [ux_dck_zpool_loop] STATE - ERR0046 Provision task is in queue
2017/08/03 14:56:11 [ux_dck_zpool_loop] STATE - ERR0046 CLOSING Provision task is in queue
2017/08/03 14:56:12 [ux_dck_zpool_loop] STATE - ERR0046 Provision task is in queue
2017/08/03 14:56:18 [ux_dck_zpool_loop] INFO  - 
2017/08/03 14:56:20 [ux_dck_zpool_loop] STATE - ERR0046 CLOSING Provision task is in queue
2017/08/03 14:56:20 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/03 14:56:22 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/03 14:56:24 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/03 14:56:26 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/03 14:56:28 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/03 14:56:30 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/03 14:56:32 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/03 14:56:34 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/03 14:56:36 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/03 14:56:38 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/03 14:56:40 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/03 14:56:42 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/03 14:56:44 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/03 14:56:46 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/03 14:56:48 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/03 14:56:50 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/03 14:56:52 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/03 14:56:54 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/03 14:56:56 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/03 14:56:58 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/03 14:57:00 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/03 14:57:02 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/03 14:57:04 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/03 14:57:06 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/03 14:57:08 [ux_dck_zpool_loop] INFO  - Trying to rejoin restarted server 192.168.100.70
2017/08/03 14:57:08 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/03 14:57:08 [ux_dck_zpool_loop] INFO  - Database started
2017/08/03 14:57:10 [ux_dck_zpool_loop] INFO  - Provisioning delete service 16a9603e-bb4c-4db4-b55f-64db67760869
2017/08/03 14:57:16 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/03 14:57:21 [ux_dck_zpool_loop] STATE - WARN0045 CLOSING Provision task is in queue
2017/08/03 14:57:22 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/03 14:57:24 [ux_dck_zpool_loop] INFO  - 12:57:14,474 disk#00        INFO    create file /srv/17311646700765639015_docker.dsk, size 1G
12:57:14,474 disk#00        INFO    provisioned
12:57:14,478 disk#00        INFO    /sbin/losetup -f /srv/17311646700765639015_docker.dsk
12:57:14,538 disk#00        INFO    /dev/loop0 now loops to /srv/17311646700765639015_docker.dsk
12:57:14,566 disk#0000      INFO    zpool create -m legacy zp17311646700765639015_00 /srv/17311646700765639015_docker.dsk
12:57:14,629 disk#0000      INFO    provisioned
12:57:14,637 disk#0000      INFO    zp17311646700765639015_00 is already up
12:57:14,646 disk#01        INFO    create file /srv/17311646700765639015_pod01.dsk, size 1G
12:57:14,646 disk#01        INFO    provisioned
12:57:14,662 disk#01        INFO    /sbin/losetup -f /srv/17311646700765639015_pod01.dsk
12:57:14,734 disk#01        INFO    /dev/loop1 now loops to /srv/17311646700765639015_pod01.dsk
12:57:14,784 disk#1001      INFO    zpool create -m legacy zp17311646700765639015_pod01 /srv/17311646700765639015_pod01.dsk
12:57:14,846 disk#1001      INFO    provisioned
12:57:14,853 disk#1001      INFO    zp17311646700765639015_pod01 is already up
12:57:14,866 fs#00          INFO    /sbin/ext4 create -p -o mountpoint=/srv/17311646700765639015/docker -o canmount=noauto zp17311646700765639015_00/docker
12:57:14,892 fs#00          INFO    /sbin/ext4 set refquota=2048M zp17311646700765639015_00/docker
12:57:14,903 fs#00          INFO    provisioned
12:57:14,921 fs#00          INFO    /sbin/ext4 mount zp17311646700765639015_00/docker
12:57:14,945 fs#01          INFO    /sbin/ext4 create -p -o mountpoint=/srv/17311646700765639015/pod01 -o canmount=noauto zp17311646700765639015_pod01/pod01
12:57:14,974 fs#01          INFO    /sbin/ext4 set refquota=1024M zp17311646700765639015_pod01/pod01
12:57:14,984 fs#01          INFO    provisioned
12:57:15,000 fs#01          INFO    /sbin/ext4 mount zp17311646700765639015_pod01/pod01
12:57:15,009 fs#01          INFO    /usr/bin/svcmgr -s 17311646700765639015 push service status;/usr/bin/svcmgr -s 17311646700765639015 compliance fix --attach --moduleset mariadb.svc.mrm.db
12:57:17,360 fs#01          INFO    output:
moduleset mariadb.svc.mrm.db attached
=========================== mariadb.svc.mrm.db.cnf ===========================
ACTION:   check
ERR: OSVC_COMP_DB_CNF_WSREP undefined substitution variable: GCOMM
ERR: failed to concatenate  to rules list
ERR: file /srv/17311646700765639015/pod01/etc/mysql/spider.cnf does not exist
ERR: file /srv/17311646700765639015/pod01/etc/mysql/myrock.cnf does not exist
ERR: file /srv/17311646700765639015/pod01/etc/mysql/compress.cnf does not exist
ERR: file /srv/17311646700765639015/pod01/etc/mysql/rc.d/ does not exist
ERR: file /srv/17311646700765639015/pod01/etc/mysql/threadpool.cnf does not exist
ERR: file /srv/17311646700765639015/pod01/data/.system/tmp/ does not exist
ERR: file /srv/17311646700765639015/pod01/etc/mysql/aria.cnf does not exist
ERR: file /srv/17311646700765639015/pod01/etc/mysql/tokudb.cnf does not exist
ERR: file /srv/17311646700765639015/pod01/etc/mysql/noquerycache.cnf does not exist
ERR: file /srv/17311646700765639015/pod01/etc/mysql/ does not exist
ERR: file /srv/17311646700765639015/pod01/etc/mysql/mysqlgtid.cnf does not exist
ERR: file /srv/17311646700765639015/pod01/data/.system/aria/ does not exist
ERR: file /srv/17311646700765639015/pod01/data/.system/repl/ does not exist
ERR: file /srv/17311646700765639015/pod01/etc/mysql/loggeneral.cnf does not exist
ERR: file /srv/17311646700765639015/pod01/etc/mysql/custom/ does not exist
ERR: file /srv/17311646700765639015/pod01/etc/mysql/security.cnf does not exist
ERR: file /srv/17311646700765639015/pod01/data/.system/innodb/redo/ does not exist
ERR: file /srv/17311646700765639015/pod01/etc/mysql/nomogslaveupdates.cnf does not exist
ERR: file /srv/17311646700765639015/pod01/etc/mysql/semisync.cnf does not exist
ERR: file /srv/17311646700765639015/pod01/etc/mysql/audit.cnf does not exist
ERR: file /srv/17311646700765639015/pod01/etc/mysql/multidomains.cnf does not exist
ERR: file /srv/17311646700765639015/pod01/data/.system/ does not exist
ERR: file /srv/17311646700765639015/pod01/etc/mysql/my.cnf does not exist
ERR: file /srv/17311646700765639015/pod01/init/ does not exist
ERR: file /srv/17311646700765639015/pod01/data/ does not exist
ERR: file /srv/17311646700765639015/pod01/etc/mysql/rpl_ptr.cnf does not exist
ERR: file /srv/17311646700765639015/pod01/data/.system/tokudb/ does not exist
ERR: file /srv/17311646700765639015/pod01/data/.system/innodb/undo/ does not exist
ERR: file /srv/17311646700765639015/pod01/etc/mysql/innodb.cnf does not exist
ERR: file /srv/17311646700765639015/pod01/init/launcher does not exist
ERR: file /srv/17311646700765639015/pod01/data/.system/innodb/ does not exist
ERR: file /srv/17311646700765639015/pod01/init/start does not exist
ERR: file /srv/17311646700765639015/pod01/etc/mysql/optimizer.cnf does not exist
ERR: file /srv/17311646700765639015/pod01/etc/mysql/optimizer.cnf does not exist
ERR: file /srv/17311646700765639015/pod01/etc/mysql/sharedpool.cnf does not exist
ERR: file /srv/17311646700765639015/pod01/init/MYSQL_ROOT_PASSWORD does not exist
ERR: file /srv/17311646700765639015/pod01/etc/mysql/smallredolog.cnf does not exist
ERR: file /srv/17311646700765639015/pod01/etc/mysql/logsqlerror.cnf does not exist
ERR: file /srv/17311646700765639015/pod01/data/.system/logs/ does not exist
ERR: file /srv/17311646700765639015/pod01/etc/mysql/logs.cnf does not exist
ERR: file /srv/17311646700765639015/pod01/etc/mysql/logslow.cnf does not exist
ERR: file /srv/17311646700765639015/pod01/etc/mysql/network.cnf does not exist
ERR: symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/smallredolog.cnf does not exist
ERR: symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/logslow.cnf does not exist
ERR: symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/threadpool.cnf does not exist
ERR: symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/noquerycache.cnf does not exist
ERR: symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/semisync.cnf does not exist
ERR: symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/innodb.cnf does not exist
ERR: symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/multidomains.cnf does not exist
STATUS:   nok
ACTION:   fixable
STATUS:   n/a
ACTION:   fix
file: mkdir /srv/17311646700765639015/pod01/etc/mysql
ERR: OSVC_COMP_DB_CNF_WSREP undefined substitution variable: GCOMM
file /srv/17311646700765639015/pod01/etc/mysql/spider.cnf rewritten
ERR: failed to concatenate  to rules list
file /srv/17311646700765639015/pod01/etc/mysql/spider.cnf mode set to 660
file /srv/17311646700765639015/pod01/etc/mysql/spider.cnf ownership set to 999:999
file /srv/17311646700765639015/pod01/etc/mysql/myrock.cnf rewritten
file /srv/17311646700765639015/pod01/etc/mysql/myrock.cnf mode set to 660
file /srv/17311646700765639015/pod01/etc/mysql/myrock.cnf ownership set to 999:999
file /srv/17311646700765639015/pod01/etc/mysql/compress.cnf rewritten
file /srv/17311646700765639015/pod01/etc/mysql/compress.cnf mode set to 660
file /srv/17311646700765639015/pod01/etc/mysql/compress.cnf ownership set to 999:999
file: mkdir /srv/17311646700765639015/pod01/etc/mysql/rc.d/
file /srv/17311646700765639015/pod01/etc/mysql/rc.d/ mode set to 775
file /srv/17311646700765639015/pod01/etc/mysql/rc.d/ ownership set to 999:999
file /srv/17311646700765639015/pod01/etc/mysql/threadpool.cnf rewritten
file /srv/17311646700765639015/pod01/etc/mysql/threadpool.cnf mode set to 660
file /srv/17311646700765639015/pod01/etc/mysql/threadpool.cnf ownership set to 999:999
file: mkdir /srv/17311646700765639015/pod01/data/.system/tmp/
file /srv/17311646700765639015/pod01/data/.system/tmp/ mode set to 775
file /srv/17311646700765639015/pod01/data/.system/tmp/ ownership set to 999:999
file /srv/17311646700765639015/pod01/etc/mysql/aria.cnf rewritten
file /srv/17311646700765639015/pod01/etc/mysql/aria.cnf mode set to 660
file /srv/17311646700765639015/pod01/etc/mysql/aria.cnf ownership set to 999:999
file /srv/17311646700765639015/pod01/etc/mysql/tokudb.cnf rewritten
file /srv/17311646700765639015/pod01/etc/mysql/tokudb.cnf mode set to 660
file /srv/17311646700765639015/pod01/etc/mysql/tokudb.cnf ownership set to 999:999
file /srv/17311646700765639015/pod01/etc/mysql/noquerycache.cnf rewritten
file /srv/17311646700765639015/pod01/etc/mysql/noquerycache.cnf mode set to 660
file /srv/17311646700765639015/pod01/etc/mysql/noquerycache.cnf ownership set to 999:999
file /srv/17311646700765639015/pod01/etc/mysql/ mode set to 775
file /srv/17311646700765639015/pod01/etc/mysql/mysqlgtid.cnf rewritten
file /srv/17311646700765639015/pod01/etc/mysql/mysqlgtid.cnf mode set to 660
file /srv/17311646700765639015/pod01/etc/mysql/mysqlgtid.cnf ownership set to 999:999
file: mkdir /srv/17311646700765639015/pod01/data/.system/aria/
file /srv/17311646700765639015/pod01/data/.system/aria/ mode set to 775
file /srv/17311646700765639015/pod01/data/.system/aria/ ownership set to 999:999
file: mkdir /srv/17311646700765639015/pod01/data/.system/repl/
file /srv/17311646700765639015/pod01/data/.system/repl/ mode set to 775
file /srv/17311646700765639015/pod01/data/.system/repl/ ownership set to 999:999
file /srv/17311646700765639015/pod01/etc/mysql/loggeneral.cnf rewritten
file /srv/17311646700765639015/pod01/etc/mysql/loggeneral.cnf mode set to 660
file /srv/17311646700765639015/pod01/etc/mysql/loggeneral.cnf ownership set to 999:999
file: mkdir /srv/17311646700765639015/pod01/etc/mysql/custom/
file /srv/17311646700765639015/pod01/etc/mysql/custom/ mode set to 775
file /srv/17311646700765639015/pod01/etc/mysql/custom/ ownership set to 999:999
file /srv/17311646700765639015/pod01/etc/mysql/security.cnf rewritten
file /srv/17311646700765639015/pod01/etc/mysql/security.cnf mode set to 660
file /srv/17311646700765639015/pod01/etc/mysql/security.cnf ownership set to 999:999
file: mkdir /srv/17311646700765639015/pod01/data/.system/innodb/redo/
file /srv/17311646700765639015/pod01/data/.system/innodb/redo/ mode set to 775
file /srv/17311646700765639015/pod01/data/.system/innodb/redo/ ownership set to 999:999
file /srv/17311646700765639015/pod01/etc/mysql/nomogslaveupdates.cnf rewritten
file /srv/17311646700765639015/pod01/etc/mysql/nomogslaveupdates.cnf mode set to 660
file /srv/17311646700765639015/pod01/etc/mysql/nomogslaveupdates.cnf ownership set to 999:999
file /srv/17311646700765639015/pod01/etc/mysql/semisync.cnf rewritten
file /srv/17311646700765639015/pod01/etc/mysql/semisync.cnf mode set to 660
file /srv/17311646700765639015/pod01/etc/mysql/semisync.cnf ownership set to 999:999
file /srv/17311646700765639015/pod01/etc/mysql/audit.cnf rewritten
file /srv/17311646700765639015/pod01/etc/mysql/audit.cnf mode set to 660
file /srv/17311646700765639015/pod01/etc/mysql/audit.cnf ownership set to 999:999
file /srv/17311646700765639015/pod01/etc/mysql/multidomains.cnf rewritten
file /srv/17311646700765639015/pod01/etc/mysql/multidomains.cnf mode set to 660
file /srv/17311646700765639015/pod01/etc/mysql/multidomains.cnf ownership set to 999:999
file /srv/17311646700765639015/pod01/data/.system/ mode set to 775
file /srv/17311646700765639015/pod01/data/.system/ ownership set to 999:999
file /srv/17311646700765639015/pod01/etc/mysql/my.cnf rewritten
file /srv/17311646700765639015/pod01/etc/mysql/my.cnf mode set to 660
file /srv/17311646700765639015/pod01/etc/mysql/my.cnf ownership set to 999:999
file: mkdir /srv/17311646700765639015/pod01/init/
file /srv/17311646700765639015/pod01/init/ mode set to 775
file /srv/17311646700765639015/pod01/init/ ownership set to 999:999
file /srv/17311646700765639015/pod01/data/ mode set to 775
file /srv/17311646700765639015/pod01/data/ ownership set to 999:999
file /srv/17311646700765639015/pod01/etc/mysql/rpl_ptr.cnf rewritten
file /srv/17311646700765639015/pod01/etc/mysql/rpl_ptr.cnf mode set to 660
file /srv/17311646700765639015/pod01/etc/mysql/rpl_ptr.cnf ownership set to 999:999
file: mkdir /srv/17311646700765639015/pod01/data/.system/tokudb/
file /srv/17311646700765639015/pod01/data/.system/tokudb/ mode set to 775
file /srv/17311646700765639015/pod01/data/.system/tokudb/ ownership set to 999:999
file: mkdir /srv/17311646700765639015/pod01/data/.system/innodb/undo/
file /srv/17311646700765639015/pod01/data/.system/innodb/undo/ mode set to 775
file /srv/17311646700765639015/pod01/data/.system/innodb/undo/ ownership set to 999:999
file /srv/17311646700765639015/pod01/etc/mysql/innodb.cnf rewritten
file /srv/17311646700765639015/pod01/etc/mysql/innodb.cnf mode set to 660
file /srv/17311646700765639015/pod01/etc/mysql/innodb.cnf ownership set to 999:999
file /srv/17311646700765639015/pod01/init/launcher rewritten
file /srv/17311646700765639015/pod01/init/launcher mode set to 755
file /srv/17311646700765639015/pod01/init/launcher ownership set to 999:999
file /srv/17311646700765639015/pod01/data/.system/innodb/ mode set to 775
file /srv/17311646700765639015/pod01/data/.system/innodb/ ownership set to 999:999
file /srv/17311646700765639015/pod01/init/start rewritten
file /srv/17311646700765639015/pod01/init/start mode set to 755
file /srv/17311646700765639015/pod01/init/start ownership set to 999:999
file /srv/17311646700765639015/pod01/etc/mysql/optimizer.cnf rewritten
file /srv/17311646700765639015/pod01/etc/mysql/optimizer.cnf mode set to 660
file /srv/17311646700765639015/pod01/etc/mysql/optimizer.cnf ownership set to 999:999
file /srv/17311646700765639015/pod01/etc/mysql/sharedpool.cnf rewritten
file /srv/17311646700765639015/pod01/etc/mysql/sharedpool.cnf mode set to 660
file /srv/17311646700765639015/pod01/etc/mysql/sharedpool.cnf ownership set to 999:999
file /srv/17311646700765639015/pod01/init/MYSQL_ROOT_PASSWORD rewritten
file /srv/17311646700765639015/pod01/init/MYSQL_ROOT_PASSWORD mode set to 660
file /srv/17311646700765639015/pod01/init/MYSQL_ROOT_PASSWORD ownership set to 999:999
file /srv/17311646700765639015/pod01/etc/mysql/smallredolog.cnf rewritten
file /srv/17311646700765639015/pod01/etc/mysql/smallredolog.cnf mode set to 660
file /srv/17311646700765639015/pod01/etc/mysql/smallredolog.cnf ownership set to 999:999
file /srv/17311646700765639015/pod01/etc/mysql/logsqlerror.cnf rewritten
file /srv/17311646700765639015/pod01/etc/mysql/logsqlerror.cnf mode set to 660
file /srv/17311646700765639015/pod01/etc/mysql/logsqlerror.cnf ownership set to 999:999
file: mkdir /srv/17311646700765639015/pod01/data/.system/logs/
file /srv/17311646700765639015/pod01/data/.system/logs/ mode set to 775
file /srv/17311646700765639015/pod01/data/.system/logs/ ownership set to 999:999
file /srv/17311646700765639015/pod01/etc/mysql/logs.cnf rewritten
file /srv/17311646700765639015/pod01/etc/mysql/logs.cnf mode set to 660
file /srv/17311646700765639015/pod01/etc/mysql/logs.cnf ownership set to 999:999
file /srv/17311646700765639015/pod01/etc/mysql/logslow.cnf rewritten
file /srv/17311646700765639015/pod01/etc/mysql/logslow.cnf mode set to 660
file /srv/17311646700765639015/pod01/etc/mysql/logslow.cnf ownership set to 999:999
file /srv/17311646700765639015/pod01/etc/mysql/network.cnf rewritten
file /srv/17311646700765639015/pod01/etc/mysql/network.cnf mode set to 660
file /srv/17311646700765639015/pod01/etc/mysql/network.cnf ownership set to 999:999
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/smallredolog.cnf -> ../smallredolog.cnf created
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/logslow.cnf -> ../logslow.cnf created
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/threadpool.cnf -> ../threadpool.cnf created
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/noquerycache.cnf -> ../noquerycache.cnf created
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/semisync.cnf -> ../semisync.cnf created
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/innodb.cnf -> ../innodb.cnf created
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/multidomains.cnf -> ../multidomains.cnf created
STATUS:   ok
ACTION:   check
file /srv/17311646700765639015/pod01/etc/mysql/spider.cnf is ok
ERR: OSVC_COMP_DB_CNF_WSREP undefined substitution variable: GCOMM
file /srv/17311646700765639015/pod01/etc/mysql/myrock.cnf is ok
ERR: failed to concatenate  to rules list
file /srv/17311646700765639015/pod01/etc/mysql/compress.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/rc.d/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/threadpool.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/tmp/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/aria.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/tokudb.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/noquerycache.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/mysqlgtid.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/aria/ is ok
file /srv/17311646700765639015/pod01/data/.system/repl/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/loggeneral.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/custom/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/security.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/innodb/redo/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/nomogslaveupdates.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/semisync.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/audit.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/multidomains.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/my.cnf is ok
file /srv/17311646700765639015/pod01/init/ is ok
file /srv/17311646700765639015/pod01/data/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/rpl_ptr.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/tokudb/ is ok
file /srv/17311646700765639015/pod01/data/.system/innodb/undo/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/innodb.cnf is ok
file /srv/17311646700765639015/pod01/init/launcher is ok
file /srv/17311646700765639015/pod01/data/.system/innodb/ is ok
file /srv/17311646700765639015/pod01/init/start is ok
file /srv/17311646700765639015/pod01/etc/mysql/optimizer.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/optimizer.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/sharedpool.cnf is ok
file /srv/17311646700765639015/pod01/init/MYSQL_ROOT_PASSWORD is ok
file /srv/17311646700765639015/pod01/etc/mysql/smallredolog.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/logsqlerror.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/logs/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/logs.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/logslow.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/network.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/smallredolog.cnf -> ../smallredolog.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/logslow.cnf -> ../logslow.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/threadpool.cnf -> ../threadpool.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/noquerycache.cnf -> ../noquerycache.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/semisync.cnf -> ../semisync.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/innodb.cnf -> ../innodb.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/multidomains.cnf -> ../multidomains.cnf is ok
STATUS:   ok
=================================== digest ===================================
0 n/a
1 passed
 mariadb.svc.mrm.db.cnf
0 error
total duration: 0:00:00.537575
12:57:17,441 container#0001 INFO    docker start 83c9084e17f7480d19a674f489d0f06de582c125eae653481663682c891a577c
12:57:17,622 container#0001 INFO    output:
83c9084e17f7480d19a674f489d0f06de582c125eae653481663682c891a577c
12:57:17,636 container#0001 INFO    wait for up status
12:57:17,664 container#0001 INFO    wait for container operational
12:57:17,709 ip#01          INFO    skip allocate: an ip is already defined
12:57:17,782 ip#01          INFO    checking 192.168.100.71 availability
12:57:20,848 ip#01          INFO    bridge mode
12:57:20,878 ip#01          INFO    create symlink /var/run/netns/19386 -> /proc/19386/ns/net
12:57:20,950 ip#01          INFO    /sbin/ip link add name veth1pl19386 mtu 1500 type veth peer name veth1pg19386 mtu 1500
12:57:20,954 ip#01          INFO    /sbin/ip link set veth1pl19386 master br-prd
12:57:20,959 ip#01          INFO    /sbin/ip link set veth1pl19386 up
12:57:20,962 ip#01          INFO    /sbin/ip link set veth1pg19386 netns 19386
12:57:20,978 ip#01          INFO    /sbin/ip netns exec 19386 ip link set veth1pg19386 name eth1
12:57:21,042 ip#01          INFO    /sbin/ip netns exec 19386 ip addr add 192.168.100.71/24 dev eth1
12:57:21,118 ip#01          INFO    /sbin/ip netns exec 19386 ip link set eth1 up
12:57:21,159 ip#01          INFO    /sbin/ip netns exec 19386 ip route replace default via 192.168.100.254
12:57:21,203 ip#01          INFO    remove /var/run/netns/19386
12:57:21,346 container#2001 INFO    docker run -d --name=17311646700765639015.container.2001 --net=container:17311646700765639015.container.0001 -e MYSQL_ROOT_PASSWORD=mariadb -e MYSQL_INITDB_SKIP_TZINFO=yes -v /etc/localtime:/etc/localtime:ro -v /srv/17311646700765639015/pod01/data:/var/lib/mysql:rw -v /srv/17311646700765639015/pod01/etc/mysql:/etc/mysql:rw -v /srv/17311646700765639015/pod01/init:/docker-entrypoint-initdb.d:rw --rm --cgroup-parent /17311646700765639015/container.docker/container.2001 mariadb:10.2
12:57:21,583 container#2001 INFO    output:
9b554ad9699eb97417b0f30a627c972f178277ddcdcce654a1a1a403cacba47d
12:57:21,606 container#2001 INFO    wait for up status
12:57:21,634 container#2001 INFO    wait for container operational
12:57:21,924                INFO    send /etc/opensvc/17311646700765639015.conf to collector
12:57:21,925                INFO    update /var/lib/opensvc/17311646700765639015/last_pushed_config timestamp
a stack has been saved to the rpc log

2017/08/03 14:57:24 [ux_dck_zpool_loop] STATE - WARN0045 CLOSING Provision task is in queue
2017/08/03 14:57:26 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/03 14:57:28 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/03 14:57:30 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/03 14:57:32 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/03 14:57:34 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/03 14:57:36 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/03 14:57:38 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/03 14:57:38 [ux_dck_zpool_loop] INFO  - Trying to rejoin restarted server 192.168.100.71
2017/08/03 14:57:38 [ux_dck_zpool_loop] STATE - INF00001 CLOSING Server 192.168.100.71 is down
2017/08/03 14:57:40 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/03 14:57:40 [ux_dck_zpool_loop] INFO  - Database started
2017/08/03 14:57:44 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/03 14:57:50 [ux_dck_zpool_loop] STATE - WARN0045 CLOSING Provision task is in queue
2017/08/03 14:57:52 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/03 14:57:57 [ux_dck_zpool_loop] INFO  - 12:57:43,480 disk#00        INFO    create file /srv/10940044185188150515_docker.dsk, size 1G
12:57:43,481 disk#00        INFO    provisioned
12:57:43,518 disk#00        INFO    /sbin/losetup -f /srv/10940044185188150515_docker.dsk
12:57:43,594 disk#00        INFO    /dev/loop2 now loops to /srv/10940044185188150515_docker.dsk
12:57:43,655 disk#0000      INFO    zpool create -m legacy zp10940044185188150515_00 /srv/10940044185188150515_docker.dsk
12:57:43,716 disk#0000      INFO    provisioned
12:57:43,723 disk#0000      INFO    zp10940044185188150515_00 is already up
12:57:43,730 disk#01        INFO    create file /srv/10940044185188150515_pod01.dsk, size 1G
12:57:43,731 disk#01        INFO    provisioned
12:57:43,784 disk#01        INFO    /sbin/losetup -f /srv/10940044185188150515_pod01.dsk
12:57:43,884 disk#01        INFO    /dev/loop3 now loops to /srv/10940044185188150515_pod01.dsk
12:57:43,959 disk#1001      INFO    zpool create -m legacy zp10940044185188150515_pod01 /srv/10940044185188150515_pod01.dsk
12:57:44,020 disk#1001      INFO    provisioned
12:57:44,027 disk#1001      INFO    zp10940044185188150515_pod01 is already up
12:57:44,038 fs#00          INFO    /sbin/ext4 create -p -o mountpoint=/srv/10940044185188150515/docker -o canmount=noauto zp10940044185188150515_00/docker
12:57:44,057 fs#00          INFO    /sbin/ext4 set refquota=2048M zp10940044185188150515_00/docker
12:57:44,067 fs#00          INFO    provisioned
12:57:44,085 fs#00          INFO    /sbin/ext4 mount zp10940044185188150515_00/docker
12:57:44,113 fs#01          INFO    /sbin/ext4 create -p -o mountpoint=/srv/10940044185188150515/pod01 -o canmount=noauto zp10940044185188150515_pod01/pod01
12:57:44,131 fs#01          INFO    /sbin/ext4 set refquota=1024M zp10940044185188150515_pod01/pod01
12:57:44,139 fs#01          INFO    provisioned
12:57:44,154 fs#01          INFO    /sbin/ext4 mount zp10940044185188150515_pod01/pod01
12:57:44,163 fs#01          INFO    /usr/bin/svcmgr -s 10940044185188150515 push service status;/usr/bin/svcmgr -s 10940044185188150515 compliance fix --attach --moduleset mariadb.svc.mrm.proxy
12:57:46,524 fs#01          INFO    output:
moduleset mariadb.svc.mrm.proxy is already attached to this service
========================= mariadb.svc.mrm.proxy.cnf ==========================
ACTION:   check
ERR: file //srv/10940044185188150515/pod01/conf/maxscale.cnf does not exist
ERR: file /srv/10940044185188150515/pod01/init/launcher does not exist
ERR: file //srv/10940044185188150515/pod01/log/ does not exist
ERR: file //srv/10940044185188150515/pod01/data/ does not exist
ERR: file //srv/10940044185188150515/pod01/conf/config-haproxy.toml does not exist
ERR: file //srv/10940044185188150515/pod01/init/ does not exist
ERR: file //srv/10940044185188150515/pod01/conf/ does not exist
ERR: file //srv/10940044185188150515/pod01/conf/keepalived.conf does not exist
ERR: file //srv/10940044185188150515/pod01/conf/config.toml does not exist
STATUS:   nok
ACTION:   fixable
STATUS:   n/a
ACTION:   fix
file: mkdir //srv/10940044185188150515/pod01/conf
file //srv/10940044185188150515/pod01/conf/maxscale.cnf rewritten
file //srv/10940044185188150515/pod01/conf/maxscale.cnf mode set to 775
file //srv/10940044185188150515/pod01/conf/maxscale.cnf ownership set to 999:999
file: mkdir /srv/10940044185188150515/pod01/init
file /srv/10940044185188150515/pod01/init/launcher rewritten
file /srv/10940044185188150515/pod01/init/launcher mode set to 755
file /srv/10940044185188150515/pod01/init/launcher ownership set to 999:999
file: mkdir //srv/10940044185188150515/pod01/log/
file //srv/10940044185188150515/pod01/log/ mode set to 775
file //srv/10940044185188150515/pod01/log/ ownership set to 999:999
file: mkdir //srv/10940044185188150515/pod01/data/
file //srv/10940044185188150515/pod01/data/ mode set to 775
file //srv/10940044185188150515/pod01/data/ ownership set to 999:999
file //srv/10940044185188150515/pod01/conf/config-haproxy.toml rewritten
file //srv/10940044185188150515/pod01/conf/config-haproxy.toml mode set to 775
file //srv/10940044185188150515/pod01/conf/config-haproxy.toml ownership set to 999:999
file //srv/10940044185188150515/pod01/init/ mode set to 775
file //srv/10940044185188150515/pod01/conf/ mode set to 775
file //srv/10940044185188150515/pod01/conf/keepalived.conf rewritten
file //srv/10940044185188150515/pod01/conf/keepalived.conf mode set to 775
file //srv/10940044185188150515/pod01/conf/keepalived.conf ownership set to 999:999
file //srv/10940044185188150515/pod01/conf/config.toml rewritten
file //srv/10940044185188150515/pod01/conf/config.toml mode set to 775
file //srv/10940044185188150515/pod01/conf/config.toml ownership set to 999:999
STATUS:   ok
ACTION:   check
file //srv/10940044185188150515/pod01/conf/maxscale.cnf is ok
file /srv/10940044185188150515/pod01/init/launcher is ok
file //srv/10940044185188150515/pod01/log/ is ok
file //srv/10940044185188150515/pod01/data/ is ok
file //srv/10940044185188150515/pod01/conf/config-haproxy.toml is ok
file //srv/10940044185188150515/pod01/init/ is ok
file //srv/10940044185188150515/pod01/conf/ is ok
file //srv/10940044185188150515/pod01/conf/keepalived.conf is ok
file //srv/10940044185188150515/pod01/conf/config.toml is ok
STATUS:   ok
=================================== digest ===================================
0 n/a
1 passed
 mariadb.svc.mrm.proxy.cnf
0 error
total duration: 0:00:00.428535
12:57:46,604 container#0001 INFO    docker start 32e4221d38e52d77ad0c9fee50fa306cdf03e0442b4d0b62855c755ffcb4422d
12:57:46,770 container#0001 INFO    output:
32e4221d38e52d77ad0c9fee50fa306cdf03e0442b4d0b62855c755ffcb4422d
12:57:46,783 container#0001 INFO    wait for up status
12:57:46,831 container#0001 INFO    wait for container operational
12:57:46,878 ip#01          INFO    skip allocate: an ip is already defined
12:57:46,945 ip#01          INFO    checking 192.168.100.75 availability
12:57:51,956 ip#01          INFO    bridge mode
12:57:51,982 ip#01          INFO    create symlink /var/run/netns/20901 -> /proc/20901/ns/net
12:57:52,053 ip#01          INFO    /sbin/ip link add name veth1pl20901 mtu 1500 type veth peer name veth1pg20901 mtu 1500
12:57:52,058 ip#01          INFO    /sbin/ip link set veth1pl20901 master br-prd
12:57:52,062 ip#01          INFO    /sbin/ip link set veth1pl20901 up
12:57:52,065 ip#01          INFO    /sbin/ip link set veth1pg20901 netns 20901
12:57:52,078 ip#01          INFO    /sbin/ip netns exec 20901 ip link set veth1pg20901 name eth1
12:57:52,130 ip#01          INFO    /sbin/ip netns exec 20901 ip addr add 192.168.100.75/24 dev eth1
12:57:52,211 ip#01          INFO    /sbin/ip netns exec 20901 ip link set eth1 up
12:57:52,246 ip#01          INFO    /sbin/ip netns exec 20901 ip route replace default via 192.168.100.254
12:57:55,306 ip#01          INFO    remove /var/run/netns/20901
12:57:55,440 container#2001 INFO    docker run -d --name=10940044185188150515.container.2001 --net=container:10940044185188150515.container.0001 -v /etc/localtime:/etc/localtime:ro -v /srv/10940044185188150515/pod01/conf:/etc/maxscale.d:rw --rm --cgroup-parent /10940044185188150515/container.docker/container.2001 asosso/maxscale:latest
12:57:55,734 container#2001 INFO    output:
8c82e69c6b5ce1316524e0e326048d2d3e22bbb8cc9683118d5e5b4866242711
12:57:55,747 container#2001 INFO    wait for up status
12:57:55,776 container#2001 INFO    wait for container operational
12:57:55,999                INFO    send /etc/opensvc/10940044185188150515.conf to collector
12:57:56,000                INFO    update /var/lib/opensvc/10940044185188150515/last_pushed_config timestamp
a stack has been saved to the rpc log

2017/08/03 14:57:58 [ux_dck_zpool_loop] STATE - WARN0045 CLOSING Provision task is in queue
2017/08/03 14:58:00 [ux_dck_zpool_loop] INFO  - Cleaning up replication on existing servers
2017/08/03 14:58:10 [ux_dck_zpool_loop] INFO  - Environment bootstrapped with 192.168.100.70 as master
2017/08/03 14:58:10 [ux_dck_zpool_loop] INFO  - Init maxscale 192.168.100.75 3307
2017/08/03 14:58:10 [ux_dck_zpool_loop] ERROR - Could not connect to MaxScale:Connection failed to address 192.168.100.75:3307
2017/08/03 14:58:10 [ux_dck_zpool_loop] STATE - ERR00012 CLOSING Could not find a master in topology
2017/08/03 14:58:10 [ux_dck_zpool_loop] STATE - ERR00021 CLOSING All cluster down in non-interactive mode
2017/08/03 14:58:10 [ux_dck_zpool_loop] STATE - ERR00010 CLOSING Could not find a slave in topology
2017/08/03 14:58:10 [ux_dck_zpool_loop] STATE - WARN0058 No GTID strict mode on slave 192.168.100.71
2017/08/03 14:58:10 [ux_dck_zpool_loop] STATE - WARN0068 No compression of binlog on slave 192.168.100.70
2017/08/03 14:58:10 [ux_dck_zpool_loop] STATE - WARN0070 No GTID strict mode on master 192.168.100.70
2017/08/03 14:58:10 [ux_dck_zpool_loop] STATE - WARN0050 No Heartbeat <= 1s on slave 192.168.100.71
2017/08/03 14:58:10 [ux_dck_zpool_loop] STATE - WARN0056 No compression of binlog on slave 192.168.100.71
2017/08/03 14:58:10 [ux_dck_zpool_loop] TEST: Waiting Bootstrap and discovery
2017/08/03 14:58:12 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Connection failed to address 192.168.100.75:3307
2017/08/03 14:58:12 [ux_dck_zpool_loop] TEST  - Waiting Bootstrap and discovery
2017/08/03 14:58:12 [ux_dck_zpool_loop] TEST  - Cluster is Bootstraped and discovery
2017/08/03 14:58:12 [ux_dck_zpool_loop] INFO  - Init maxscale 192.168.100.75 3307
2017/08/03 14:58:12 [ux_dck_zpool_loop] ERROR - Could not connect to MaxScale:Connection failed to address 192.168.100.75:3307
2017/08/03 14:58:12 [ux_dck_zpool_loop] TEST  - Starting Test testFailoverSemisyncAutoRejoinSafeMSMXXXRXSMS
2017/08/03 14:58:13 [ux_dck_zpool_loop] BENCH - PreparedExecConcurrent2 10 iterations
 34.651478ms 	    289 queries/sec	    8 allocs/query	    818 B/query

Finished... Total running time: 51.899945ms

2017/08/03 14:58:16 [ux_dck_zpool_loop] STATE - ERR00018 CLOSING Could not connect to MaxScale: Connection failed to address 192.168.100.75:3307
2017/08/03 14:58:20 [ux_dck_zpool_loop] ALERT - Server 192.168.100.71 state changed from Slave to Suspect
2017/08/03 14:58:20 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/03 14:58:20 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/03 14:58:20 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/03 14:58:20 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.71 is down
2017/08/03 14:58:20 [ux_dck_zpool_loop] STATE - ERR00010 Could not find a slave in topology
2017/08/03 14:58:25 [ux_dck_zpool_loop] INFO  - Declaring server 192.168.100.71 as failed
2017/08/03 14:58:25 [ux_dck_zpool_loop] ALERT - Server 192.168.100.71 state changed from Suspect to Failed
2017/08/03 14:58:39 [ux_dck_zpool_loop] INFO  - Master Failure detected! Retry 1/3
2017/08/03 14:58:39 [ux_dck_zpool_loop] ALERT - Server 192.168.100.70 state changed from StandAlone to Suspect
2017/08/03 14:58:43 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/03 14:58:43 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/03 14:58:43 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/03 14:58:44 [ux_dck_zpool_loop] INFO  - Master Failure detected! Retry 2/3
2017/08/03 14:58:47 [ux_dck_zpool_loop] TEST  - Starting Database service 17311646700765639015
2017/08/03 14:58:48 [ux_dck_zpool_loop] STATE - ERR00012 Could not find a master in topology
2017/08/03 14:58:48 [ux_dck_zpool_loop] STATE - ERR00021 All cluster down in non-interactive mode
2017/08/03 14:58:48 [ux_dck_zpool_loop] ERROR - Error 2003: Lost connection to backend server.
2017/08/03 14:58:49 [ux_dck_zpool_loop] INFO  - Declaring server 192.168.100.70 as failed
2017/08/03 14:58:49 [ux_dck_zpool_loop] ALERT - Server 192.168.100.70 state changed from Suspect to Failed
2017/08/03 14:58:49 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 14:58:51 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 14:58:53 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 14:58:55 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 14:58:57 [ux_dck_zpool_loop] STATE - ERR00010 CLOSING Could not find a slave in topology
2017/08/03 14:58:57 [ux_dck_zpool_loop] ERROR - Slave wants to rejoin non discovered master
2017/08/03 14:58:57 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 14:58:59 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 14:59:01 [ux_dck_zpool_loop] STATE - ERR00021 CLOSING All cluster down in non-interactive mode
2017/08/03 14:59:01 [ux_dck_zpool_loop] STATE - WARN0058 No GTID strict mode on slave 192.168.100.71
2017/08/03 14:59:01 [ux_dck_zpool_loop] STATE - WARN0050 No Heartbeat <= 1s on slave 192.168.100.71
2017/08/03 14:59:01 [ux_dck_zpool_loop] STATE - WARN0056 No compression of binlog on slave 192.168.100.71
2017/08/03 14:59:01 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 14:59:03 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 14:59:05 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 14:59:07 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 14:59:09 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 14:59:11 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 14:59:13 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 14:59:15 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 14:59:17 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 14:59:19 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 14:59:21 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 14:59:23 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 14:59:25 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 14:59:27 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 14:59:29 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 14:59:31 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 14:59:33 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 14:59:35 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 14:59:37 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 14:59:39 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 14:59:41 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 14:59:43 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 14:59:45 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 14:59:47 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 14:59:47 [ux_dck_zpool_loop] INFO  - Rejoin timeout
2017/08/03 14:59:52 [ux_dck_zpool_loop] TEST  - Starting Database service 4832677178583133704
2017/08/03 14:59:54 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 14:59:56 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 14:59:58 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 15:00:00 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 15:00:02 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 15:00:04 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 15:00:06 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 15:00:06 [ux_dck_zpool_loop] INFO  - Trying to rejoin restarted server 192.168.100.70
2017/08/03 15:00:06 [ux_dck_zpool_loop] STATE - INF00001 CLOSING Server 192.168.100.70 is down
2017/08/03 15:00:06 [ux_dck_zpool_loop] STATE - ERR00012 CLOSING Could not find a master in topology
2017/08/03 15:00:06 [ux_dck_zpool_loop] STATE - WARN0068 No compression of binlog on slave 192.168.100.70
2017/08/03 15:00:06 [ux_dck_zpool_loop] STATE - WARN0070 No GTID strict mode on master 192.168.100.70
2017/08/03 15:00:08 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 15:00:10 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 15:00:12 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 15:00:14 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 15:00:16 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 15:00:18 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 15:00:20 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 15:00:22 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 15:00:24 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 15:00:26 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 15:00:28 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 15:00:30 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 15:00:32 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 15:00:34 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 15:00:36 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 15:00:38 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 15:00:40 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 15:00:42 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 15:00:44 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 15:00:46 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 15:00:48 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 15:00:50 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 15:00:52 [ux_dck_zpool_loop] TEST  - Waiting Rejoin
2017/08/03 15:00:52 [ux_dck_zpool_loop] INFO  - Rejoin timeout
2017/08/03 15:01:07 [ux_dck_zpool_loop] INFO  - Checksum master table replication_manager_schema.bench =  344827675 192.168.100.70
2017/08/03 15:01:07 [ux_dck_zpool_loop] INFO  - Number of rows master table replication_manager_schema.bench = 33 192.168.100.70
2017/08/03 15:01:07 [ux_dck_zpool_loop] INFO  - Max Value in bench table replication_manager_schema.bench = 11 192.168.100.70
2017/08/03 15:01:07 [ux_dck_zpool_loop] INFO  - Checksum slave table replication_manager_schema.bench = 344827675 on 192.168.100.71 
2017/08/03 15:01:07 [ux_dck_zpool_loop] INFO  - Number of rows slave table replication_manager_schema.bench =  33 192.168.100.71
2017/08/03 15:01:07 [ux_dck_zpool_loop] INFO  - Max Value in bench table replication_manager_schema.bench = 11 192.168.100.71
2017/08/03 15:01:08 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/03 15:01:08 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/03 15:01:08 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/03 15:01:08 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/03 15:01:08 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/03 15:01:08 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/03 15:01:08 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/03 15:01:10 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/03 15:01:10 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/03 15:01:10 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/03 15:01:10 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/03 15:01:10 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/03 15:01:10 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/03 15:01:10 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/03 15:01:10 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/03 15:01:10 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/03 15:01:13 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/03 15:01:13 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/03 15:01:13 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/03 15:01:13 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/03 15:01:13 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/03 15:01:13 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/03 15:01:13 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/03 15:01:13 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/03 15:01:13 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/03 15:01:13 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/03 15:01:15 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/03 15:01:15 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/03 15:01:15 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/03 15:01:15 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/03 15:01:15 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/03 15:01:15 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/03 15:01:15 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/03 15:01:15 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/03 15:01:15 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/03 15:01:15 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/03 15:01:17 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/03 15:01:17 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/03 15:01:17 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/03 15:01:17 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/03 15:01:17 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/03 15:01:17 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/03 15:01:17 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/03 15:01:17 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/03 15:01:17 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/03 15:01:17 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/03 15:01:19 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/03 15:01:19 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/03 15:01:19 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/03 15:01:19 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/03 15:01:19 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/03 15:01:19 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/03 15:01:19 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/03 15:01:19 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/03 15:01:19 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/03 15:01:19 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/03 15:01:21 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/03 15:01:21 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/03 15:01:21 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/03 15:01:21 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/03 15:01:21 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/03 15:01:21 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/03 15:01:21 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/03 15:01:21 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/03 15:01:21 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/03 15:01:21 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/03 15:01:23 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/03 15:01:23 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/03 15:01:23 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/03 15:01:23 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/03 15:01:23 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/03 15:01:23 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/03 15:01:23 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/03 15:01:23 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/03 15:01:23 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/03 15:01:23 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/03 15:01:25 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/03 15:01:25 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/03 15:01:25 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/03 15:01:25 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/03 15:01:25 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/03 15:01:25 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/03 15:01:25 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/03 15:01:25 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/03 15:01:25 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/03 15:01:25 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/03 15:01:27 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/03 15:01:27 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/03 15:01:27 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/03 15:01:27 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/03 15:01:27 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/03 15:01:27 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/03 15:01:27 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/03 15:01:27 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/03 15:01:27 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/03 15:01:27 [ux_dck_zpool_loop] ERROR - Error 1045: failed to create new session
2017/08/03 15:01:29 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/03 15:01:31 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/03 15:01:31 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/03 15:01:31 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/03 15:01:31 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/03 15:01:31 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/03 15:01:31 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/03 15:01:31 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/03 15:01:31 [ux_dck_zpool_loop] ERROR - dial tcp 192.168.100.75:4007: getsockopt: connection refused
2017/08/03 15:01:31 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/03 15:01:31 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/03 15:01:32 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/03 15:01:33 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/03 15:01:33 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/03 15:01:33 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/03 15:01:33 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/03 15:01:33 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/03 15:01:33 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/03 15:01:33 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/03 15:01:33 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/03 15:01:33 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/03 15:01:34 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/03 15:01:34 [ux_dck_zpool_loop] ERROR - dial tcp 192.168.100.75:4007: i/o timeout
2017/08/03 15:01:35 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/03 15:01:35 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/03 15:01:35 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/03 15:01:35 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/03 15:01:35 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/03 15:01:35 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/03 15:01:35 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/03 15:01:35 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/03 15:01:35 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/03 15:01:36 [ux_dck_zpool_loop] ERROR - dial tcp 192.168.100.75:4007: i/o timeout
2017/08/03 15:01:36 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/03 15:01:37 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/03 15:01:37 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/03 15:01:37 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/03 15:01:37 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/03 15:01:37 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/03 15:01:37 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/03 15:01:37 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/03 15:01:37 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/03 15:01:37 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/03 15:01:38 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/03 15:01:38 [ux_dck_zpool_loop] ERROR - dial tcp 192.168.100.75:4007: i/o timeout
2017/08/03 15:01:39 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/03 15:01:39 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/03 15:01:39 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/03 15:01:39 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/03 15:01:39 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/03 15:01:39 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/03 15:01:39 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/03 15:01:39 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/03 15:01:39 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/03 15:01:40 [ux_dck_zpool_loop] ERROR - dial tcp 192.168.100.75:4007: i/o timeout
2017/08/03 15:01:40 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/03 15:01:41 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/03 15:01:41 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/03 15:01:41 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/03 15:01:41 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/03 15:01:41 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/03 15:01:41 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/03 15:01:41 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/03 15:01:41 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/03 15:01:41 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/03 15:01:42 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/03 15:01:42 [ux_dck_zpool_loop] ERROR - dial tcp 192.168.100.75:4007: i/o timeout
2017/08/03 15:01:43 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/03 15:01:43 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/03 15:01:43 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/03 15:01:43 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/03 15:01:43 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/03 15:01:43 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/03 15:01:43 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/03 15:01:43 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/03 15:01:43 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/03 15:01:44 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/03 15:01:44 [ux_dck_zpool_loop] ERROR - dial tcp 192.168.100.75:4007: i/o timeout
2017/08/03 15:01:45 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/03 15:01:45 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/03 15:01:45 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/03 15:01:45 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/03 15:01:45 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/03 15:01:45 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/03 15:01:45 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/03 15:01:45 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/03 15:01:45 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/03 15:01:46 [ux_dck_zpool_loop] ERROR - dial tcp 192.168.100.75:4007: i/o timeout
2017/08/03 15:01:46 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/03 15:01:47 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/03 15:01:47 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/03 15:01:47 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/03 15:01:47 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/03 15:01:47 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/03 15:01:47 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/03 15:01:47 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/03 15:01:47 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/03 15:01:47 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/03 15:01:48 [ux_dck_zpool_loop] ERROR - dial tcp 192.168.100.75:4007: i/o timeout
2017/08/03 15:01:48 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/03 15:01:49 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/03 15:01:49 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/03 15:01:49 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/03 15:01:49 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/03 15:01:49 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/03 15:01:49 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/03 15:01:49 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/03 15:01:49 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/03 15:01:49 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/03 15:01:50 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/03 15:01:50 [ux_dck_zpool_loop] ERROR - dial tcp 192.168.100.75:4007: i/o timeout
2017/08/03 15:01:51 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/03 15:01:51 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/03 15:01:51 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/03 15:01:51 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/03 15:01:51 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/03 15:01:51 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/03 15:01:51 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/03 15:01:51 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/03 15:01:51 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/03 15:01:52 [ux_dck_zpool_loop] ERROR - dial tcp 192.168.100.75:4007: i/o timeout
2017/08/03 15:01:52 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/03 15:01:53 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/03 15:01:53 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/03 15:01:53 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/03 15:01:53 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/03 15:01:53 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/03 15:01:53 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/03 15:01:53 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/03 15:01:53 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/03 15:01:53 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/03 15:01:54 [ux_dck_zpool_loop] ERROR - dial tcp 192.168.100.75:4007: i/o timeout
2017/08/03 15:01:54 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/03 15:01:55 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/03 15:01:55 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/03 15:01:55 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/03 15:01:55 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/03 15:01:55 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/03 15:01:55 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/03 15:01:55 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/03 15:01:55 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/03 15:01:55 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/03 15:01:56 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/03 15:01:56 [ux_dck_zpool_loop] ERROR - dial tcp 192.168.100.75:4007: i/o timeout
2017/08/03 15:01:57 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/03 15:01:57 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/03 15:01:57 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/03 15:01:57 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/03 15:01:57 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/03 15:01:57 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/03 15:01:57 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/03 15:01:57 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/03 15:01:57 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/03 15:01:58 [ux_dck_zpool_loop] ERROR - dial tcp 192.168.100.75:4007: i/o timeout
2017/08/03 15:01:58 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/03 15:01:59 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/03 15:01:59 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/03 15:01:59 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/03 15:01:59 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/03 15:01:59 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/03 15:01:59 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/03 15:01:59 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/03 15:01:59 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/03 15:01:59 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/03 15:02:00 [ux_dck_zpool_loop] INFO  - hostlist: 192.168.100.70,192.168.100.71 [192.168.100.70 192.168.100.71]
2017/08/03 15:02:00 [ux_dck_zpool_loop] INFO  - Loading 1 proxies
2017/08/03 15:02:00 [ux_dck_zpool_loop] INFO  - Loading Maxscale...
2017/08/03 15:02:00 [ux_dck_zpool_loop] TEST  - Result FailoverSemisyncAutoRejoinSafeMSMXXXRXSMS                -> {testFailoverSemisyncAutoRejoinSafeMSMXXXRXSMS PASS ././config/masterslave/mariadb/with_traffic/10.2/x2/multidomains/innodb/maxscale/latest/x1/replication-manager.conf {/var/lib/replication-manager /usr/local/share/mrm root:mariadb 192.168.100.70,192.168.100.71     root:mariadb %!s(bool=false) %!s(bool=false)    192.168.100.70  %!s(int64=5000) %!s(int64=10) %!s(int=10) %!s(bool=false) %!s(bool=false) %!s(int64=0) %!s(bool=true) %!s(bool=true) %!s(bool=true) %!s(bool=true) %!s(bool=true) %!s(bool=true) ./config/masterslave/mariadb/with_traffic/10.2/x2/multidomains/innodb/maxscale/latest/x1/1.1.0-preview3-98-gc4fd436/testFailoverSemisyncAutoRejoinSafeMSMXXXRXSMS.log %!s(int64=2) %!s(int=1) tcp %!s(bool=true) %!s(bool=true) %!s(bool=false) %!s(int=3) %!s(int=5) %!s(bool=false) %!s(bool=false) %!s(bool=true) %!s(bool=true) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(uint64=1000000000) %!s(bool=true) %!s(bool=true) %!s(bool=false) %!s(bool=true)  %!s(bool=false) %!s(bool=false) %!s(bool=false) localhost 10001 %!s(bool=true) ../../dashboard %!s(bool=false) %!s(bool=true) %!s(int=3600) %!s(bool=true) mrm@localhost  localhost:25 %!s(int=10) %!s(int=999) %!s(int64=1) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(int=3) %!s(int64=300) %!s(int64=0) %!s(bool=false) %!s(bool=false) %!s(int=3) %!s(int=14) %!s(bool=false) %!s(int=80) %!s(bool=false) %!s(bool=false) 127.0.0.1:3307 admin %!s(bool=true) 192.168.100.75 3307 admin mariadb %!s(int=4007) %!s(int=4008) %!s(int=4006) %!s(int=3307) %!s(bool=false) %!s(int=3309) %!s(bool=false) maxadmin %!s(bool=false) %!s(bool=false) %!s(int=3306) %!s(int=3307) %!s(int=1988) 0.0.0.0 0.0.0.0 /usr/sbin/haproxy /etc/replication-manager/.replication-manager.key %!s(int=0) %!s(bool=true) %!s(bool=true) unknown %!s(bool=false) %!s(bool=false) 127.0.0.1 %!s(int=2003) %!s(int=10002) %!s(int=10003) %!s(int=7002) %!s(int=2004) %!s(int=7007) /usr/local/bin/sysbench %!s(int=60) %!s(int=4) /usr/local/mysql/bin %!s(bool=false)  88.191.151.84:80 %!s(int=0) 127.0.0.1:10002 %!s(bool=false) %!s(bool=true) %!s(bool=false) %!s(bool=true) 192.168.100.101:443 root@localhost.localdomain:opensvc replication-manager@localhost.localdomain:mariadb docker node-1-1.vdc.opensvc.com,node-1-2.vdc.opensvc.com 256 300 smallredolog,semisync,innodb,noquerycache,threadpool,logslow,multidomains 1G ext4 zpool /srv loopback br-prd 255.255.255.0 192.168.100.254 docker node-1-2.vdc.opensvc.com 1G ext4 zpool /srv loopback br-prd 255.255.255.0 192.168.100.254     mariadb:10.2 asosso/maxscale:latest admin:mariadb 3000 ././config/masterslave/mariadb/with_traffic/10.2/x2/multidomains/innodb/maxscale/latest/x1/replication-manager.conf} {/var/lib/replication-manager /usr/local/share/mrm root:mariadb 192.168.100.70,192.168.100.71     root:mariadb %!s(bool=false) %!s(bool=false)    192.168.100.70  %!s(int64=5000) %!s(int64=10) %!s(int=10) %!s(bool=false) %!s(bool=false) %!s(int64=0) %!s(bool=true) %!s(bool=true) %!s(bool=true) %!s(bool=true) %!s(bool=true) %!s(bool=true) ./config/masterslave/mariadb/with_traffic/10.2/x2/multidomains/innodb/maxscale/latest/x1/1.1.0-preview3-98-gc4fd436/testFailoverSemisyncAutoRejoinSafeMSMXXXRXSMS.log %!s(int64=2) %!s(int=1) tcp %!s(bool=true) %!s(bool=true) %!s(bool=false) %!s(int=3) %!s(int=5) %!s(bool=false) %!s(bool=false) %!s(bool=true) %!s(bool=true) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(uint64=1000000000) %!s(bool=true) %!s(bool=true) %!s(bool=false) %!s(bool=false)  %!s(bool=false) %!s(bool=false) %!s(bool=false) localhost 10001 %!s(bool=true) ../../dashboard %!s(bool=false) %!s(bool=true) %!s(int=3600) %!s(bool=true) mrm@localhost  localhost:25 %!s(int=10) %!s(int=999) %!s(int64=0) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(int=3) %!s(int64=300) %!s(int64=0) %!s(bool=false) %!s(bool=false) %!s(int=3) %!s(int=14) %!s(bool=false) %!s(int=80) %!s(bool=false) %!s(bool=false) 127.0.0.1:3307 admin %!s(bool=true) 192.168.100.75 3307 admin mariadb %!s(int=4007) %!s(int=4008) %!s(int=4006) %!s(int=3307) %!s(bool=false) %!s(int=3309) %!s(bool=false) maxadmin %!s(bool=false) %!s(bool=false) %!s(int=3306) %!s(int=3307) %!s(int=1988) 0.0.0.0 0.0.0.0 /usr/sbin/haproxy /etc/replication-manager/.replication-manager.key %!s(int=0) %!s(bool=true) %!s(bool=true) master-slave %!s(bool=false) %!s(bool=false) 127.0.0.1 %!s(int=2003) %!s(int=10002) %!s(int=10003) %!s(int=7002) %!s(int=2004) %!s(int=7007) /usr/local/bin/sysbench %!s(int=60) %!s(int=4) /usr/local/mysql/bin %!s(bool=false)  88.191.151.84:80 %!s(int=0) 127.0.0.1:10002 %!s(bool=false) %!s(bool=true) %!s(bool=false) %!s(bool=true) 192.168.100.101:443 root@localhost.localdomain:opensvc replication-manager@localhost.localdomain:mariadb docker node-1-1.vdc.opensvc.com,node-1-2.vdc.opensvc.com 256 300 smallredolog,semisync,innodb,noquerycache,threadpool,logslow,multidomains 1G ext4 zpool /srv loopback br-prd 255.255.255.0 192.168.100.254 docker node-1-2.vdc.opensvc.com 1G ext4 zpool /srv loopback br-prd 255.255.255.0 192.168.100.254     mariadb:10.2 asosso/maxscale:latest admin:mariadb 3000 ././config/masterslave/mariadb/with_traffic/10.2/x2/multidomains/innodb/maxscale/latest/x1/replication-manager.conf}}
